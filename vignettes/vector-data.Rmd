---
title: "Unit 2 - Working with Vector Data"
author: "Lyndon Estes, Zhiwen Zhu"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    fig_caption: yes
    number_sections: yes
    toc_depth: 3
    toc: yes
vignette: >
  %\VignetteIndexEntry{Unit 2: Vector data}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

<style type="text/css">

body{ /* Normal  */
      font-size: 12px;
  }
td {  /* Table  */
  font-size: 12px;
}
h1.title {
  font-size: 38px;
  <!-- color: DarkRed; -->
}
h1 { /* Header 1 */
  font-size: 28px;
  <!-- color: DarkBlue; -->
}
h2 { /* Header 2 */
    font-size: 22px;
  <!-- color: DarkBlue; -->
}
h3 { /* Header 3 */
  font-size: 18px;
  <!-- font-family: "Times New Roman", Times, serif; -->
  <!-- color: DarkBlue; -->
}
code.r{ /* Code block */
    font-size: 12px;
}
pre { /* Code block - determines code spacing between lines */
    font-size: 14px;
}
</style>

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)
```

# Introduction{#vectorintro}

In this section we are going to use R to work with vector data, learning the most common forms of spatial operations that work with vector data. This means we will be working primarily with the following packages: `sp`, `rgdal`, and `rgeos`. We will touch on, towards the end, the new `sf` package, which is new but already more powerful than `sp`, which it is designed to replace. Okay, so why are we learning about `sp`? Please ask me about that in class! 

The material in this section assumes that the reader is familiar with standard GIS operations and concepts, ranging from projections and transformations to intersections, buffers, and differencing.  It also assumes that you have already read Chapter 2 in _Applied Spatial Data Analysis with R_ (ASDAR), and know the basics of R spatial classes.

The reading is designed with the expectation that you work through the code as you read through it. It mixes code and explanation of the code with some exercises to practice on your own. Additionally, you should also look at the help file for each new function that is introduced, in order to familiarize yourself with the arguments. 

[Back to top](#vectorintro)

# Preparation
## Working space
We present here a mix of explanation with code and exercises to help you learn it. We recommend that you work through these readings as follows: 

1. Create a new folder under your favorite installation directory. Call it `unit2` os something similar. Make two sub-folders underneath that, one called `data`, the other `scratch`.

2. Under the `scratch` folder, create a new script file called "readings.R". The first line of this should call `library(geospaar)`. Below this, you can paste in and work through the code provided by the reading, including any code we ask you to create as part of the in-reading exercises.  

3. Read and write any data we ask you to create as part of the exercises to the "data" folder. 

4. Before each reading, remember to reinstall `geospaar` to get the latest version.

## Installations

Let's start by loading the following packages.
```{r, warning=FALSE, message=FALSE}
library(sp)
library(rgdal)
library(geospaar)
```

`sp` you should already know about from your ASDAR reading. `rgdal` is something you probably haven't looked into much yet, so what is it?  This is a package that, according to `rgdal`'s DESCRIPTION file: 

    Provides bindings to the Geospatial Data Abstraction Library ('GDAL') (>= 1.6.3) and access to projection/transformation operations from the 'PROJ.4' library. The 'GDAL' and 'PROJ.4' libraries are external to the package, and, when installing the package from source, must be correctly installed first. Both 'GDAL' raster and 'OGR' vector map data can be imported into R, and 'GDAL' raster data and 'OGR' vector data exported.

That means that `rgdal` allows us to call these external libraries that give us the ability to read in a wide range of raster and vector formats, provided we have these libraries already installed on our computer.  

So, you probably have to install these first. Platform specific instructions follow.

### Windows

You should be able to do most of the work in this section by simply installing the `rgdal` library.  

### Mac
The same holds as for Windows (just install `rgdal`), but you might also have to install the full GDAL and PROJ.4 libraries. The easiest way to do that is to go to William Kyngesburye's website to [download the latest QGIS version](http://www.kyngchaos.com/software/qgis), which as of writing (9 October, 2017) is 2.18.13-1. The installer bundles in GDAL and PROJ.4 along with QGIS, doing it all for you in one go.  Read the page first and then the various readme's accompanying the install files you extract from the .dmg. 

[Back to top](#vectorintro)

# Section 1

This reading introduces reading, writing, and making vector data, how to work with their coordinate reference systems (crs), and how to do some basic plotting, leavened with some additional R programming examples. There are 5 self-examination exercises interspersed throughout the text. You can jump to them from here: 
Exercises [#1](#exercise1), [#2](#exercise2), [#3](#exercise3), [#4](#exercise4), and [#5](#exercise5) 

## Reading, writing, and making vector data
### From non-spatial to `SpatialPoints`

We are going to start by reading in another permutation of the farmer dataset that you were working with in Unit 1, but this time it comes with spatial data attached.  These data ship with `geospaar` version 0.3.5+, and are currently in .csv format. 

```{r}
farmers <- read.csv(system.file("extdata/farmer_spatial.csv", 
                                package = "geospaar"), stringsAsFactors = FALSE)
head(farmers)
```

Okay, so this looks similar to what we had before, but now we have a "lat" and a "lon" column, and are also missing the "mm" column.  First, check the class of the `farmers`. It will show you that it is a `data.frame`, which means it is non-spatial at the moment.  But we can see that we have some coordinates there, and they are in decimal degree format. Given that these are point data, we can turn them into a facsimile of spatial data by simply plotting them and having a look. 

```{r, fig.align='center'}
plot(x = farmers$lon, y = farmers$lat, pch = 20, cex = 0.5)
```

So that shows you, in a very crude way, where these points lie in space, given that `farmers$lon` (the longitude) is exactly analogous to the x coordinate of a scatter plot, and `farmers$lat` (latitude) is the y coordinate. But it is still not a spatial object. So, let's convert it to one, and then plot it again.

```{r, fig.align='center'}
coordinates(farmers) <- ~lon + lat
head(farmers)
plot(farmers, pch = 20, cex = 0.5)
```

Now, a few things about the code above and results above. ___First___, if you compare the result of `head (farmers)` to the previous version, you will see the "lat" and "lon" columns have disappeared and are replaced by the "coordinates" column. ___Next___, notice how `plot` is used. It applies to the entire object `farmers`, and the output plot looks somewhat different than the previous version. This is the result of having promoted `farmers` from a `data.frame` to a spatial object, and the plot function operates differently on a spatial object than it does for ordinary vectors. ___Third___, the promotion was accomplished by the first line of code in the block above. There are a few things about that line that might seem curious: the "~" and the lack of quotes around the column names on the right hand side of the operator (`<-`); the function being applied to an object on the left hand side of the assignment operator (`coordinates(farmers)`). You have seen the latter aspect before in Unit 1, but we never really talked about it (for example, when changing a `data.frame`'s column names: `colnames(dat) <- c("a", "b")`). Suffice to say, this sort of syntax means you are modifying the properties of an existing object (in this case, we are changing a `data.frame` into something spatial).

Now, what sort of spatial object is `farmers` after this promotion? 

```{r}
class(farmers)
```

Gives the answer. We can _coerce_, or demote, `farmers` back to an ordinary `data.frame` by simply doing this: 

```{r}
farmers <- as.data.frame(farmers)
class(farmers)
```

We can also simply convert `farmers` coordinates to `SpatialPoints`, a simpler spatial class that lacks the accompanying `data.frame`. We are not going to show that here, because that is your first exercise to complete [<span style="color:blue">Exercise 1</span><a name="exercise1"></a>].

Let's move on and keep working with `farmers` as a `SpatialPointsDataFrame`, so your next exercise is to promote `farmers` back to a `SpatialPointsDataFrame` [<span style="color:blue">Exercise 2</span><a name="exercise2"></a>]. 

```{r, echo = FALSE}
coordinates(farmers) <- ~lon + lat  # notice ~ and the lack of encloding ""
```

[Back to top](#vectorintro)

### Read and write spatial data 

We are going to do some reading and writing (in reverse order) of spatial data now. You should now have `farmers` back as a `r class(farmers)`. And you should have a "data" folder under your "unit2" working folder. My folder lives here`geospaar/external/unit2/data`, which is convenient for me to keep where course material is developed, but is ignored by `devtools` during package building, and which I do not commit to geospaar's repo), so in the next step I am going to use the function `writeOGR` from the `rgdal` package to write `farmers` as an ESRI shapefile out to that folder. Follow along, ___but change the file path to correctly lead to your own `unit2/data` path___ (note in the construction below, I have `../external/unit2/`, which is necessary for the function to run and find my `geospaar/external/unit2/` because when the vignette that I am writing this in knits, it starts from the `geospaar/vignettes`, so needs to go back up one directory level first--you probably don't need to do this)

```{r, eval = FALSE}
writeOGR(obj = farmers,
         dsn = "../external/unit2/data/farmers.shp",
         layer = "farmers", driver = "ESRI Shapefile",
         overwrite_layer = TRUE)
```

The above creates that old standby, the ESRI shapefile, that clunky, annoying format that has many files for one thing. Note that I have the option `overwrite_layer = TRUE` set, which needs to be set if the file already exists in that location, and you want to recreate it (which I did in this case, because I was running this code many times as I wrote this). 

If you look in your output directory, you will note that there are only three files now (.dbf, .shp, and .shx). We are missing a .prj because of the following reason: 

```{r}
proj4string(farmers)
```

`farmers` does not have a coordinate reference system (CRS) associated with it yet, even though we can tell it is in geographic coordinates.  Remember this, because we will come back to it. 

Because .shp is an annoying format, we can try other types. Let's do the much more convenient "SQLite" format, which produces a single file.  
```{r, eval = FALSE}
writeOGR(obj = farmers, dsn = "../external/unit2/data/farmers.sqlite",
         layer = "farmers", driver = "SQLite")
```

Note that you can see what output formats you can use by using the function `ogrDrivers`. Here's a look at the head of it, but you can explore the output data.frame it produces (you will see Idrisi in there also).  
```{r}
head(ogrDrivers())
```

Right, let's read that back in now, but just pulling from the shapefile itself. I am going the first delete the .sqlite version, for the sake of directory cleanliness (having shown you a nicer format, I am not going to work with because so much is still done with ESRI shapefiles, so we must as well remain used to them) 
```{r, eval = FALSE}
file.remove("../external/unit2/data/farmers.sqlite")
rm(farmers) 
farmers <- readOGR(dsn = "../external/unit2/data/farmers.shp",
                   layer = "farmers")
```

Okay, so I used `file.remove` to get rid of the .sqlite, and then used `rm` to get rid of the existing `farmers` `r class(farmers)`, and then read back in the `farmers` I had written to the .shp. So I have `farmers` back again.   

Now, there are two more datasets that come with `geospaar` to read in using `readOGR`: `roads.shp` and `districts.shp`. The paths to both are found with the `system.file` function. I'll set up the first one for you. 
```{r}
fnm <- system.file("extdata/roads.shp", package = "geospaar")
roads <- readOGR(dsn = fnm, layer = "roads")
```

Notice how the `dsn` (data source name) argument contains the full file name and path to it, while `layer` matches the file name, but without the extension. Sometimes you will try read in spatial data where the layer name is something different, and the read operation will fail. How can you possibly find out in such cases what the correct layer name is? Well, one way is to open up the fail in a standard GIS software such as ArcGIS or QGIS, and look at the layer's properties that way. But we don't have to leave R, as we can use `rgdal::ogrInfo()` 

```{r}
roads_info <- ogrInfo(fnm)
roads_info
str(roads_info)
roads_info
roads_info$layer
```

A very handy function that reads the spatial file on disk and returns a bunch of useful metadata about it within a list of class `r class(roads_info)`, including the layer name. 

Now, your next exercise is to use `readOGR` to load `districts.shp` into a new object called `districts`, and then figure out the classes of both `roads` and `districts`. Also look at the structure of each object [<span style="color:blue">Exercise 3</span><a name="exercise3"></a>].

Once you have those done all of that, let's end this section by a quick look at these data. We are going to plot `districts`, `roads`, and `farmers` all onto one plot.   
```{r, echo=FALSE}
data(roads)
data(districts)
```
```{r, fig.align='center'}
par(mar = c(0, 0, 0, 0))
plot(districts, col = "grey")
lines(roads, col = "red")
points(farmers, pch = 20, col = "blue")
```

Okay, so what have we done? First, we use the `par` function with the `mar` (margin) argument and a 4-element vector of 0s to remove the inner margins of the plot so that the map of Zambia fills the plot frame. We then use `plot` to draw the map of `districts`, which are administrative boundaries for Zambia. We then use lines to add `roads` on top of that, making them red. Finally, we add the `farmers` data as blue points. Note that all these plotting functions we have used before in Unit 1 for non-spatial objects. 

That's great, you say, but I see no `roads` in the map. Where are they? And why are there two farmers outside of Zambia?  

We'll look at that in our next section.  

[Back to top](#vectorintro)

## Coordinate Reference Systems and Projections

The reason you can't see the roads on the previous map can be illustrated as follows: 

```{r}
spdat <- list("districts" = districts,  "roads" = roads, "farmers" = farmers)
spdat_boxes <- sapply(spdat, function(x) bbox(x))
rownames(spdat_boxes) <- c("xmin", "ymin", "xmax", "ymax")
spdat_boxes
```

In the code above, I added all of our spatial datasets into a `list` (`spdat`), and then ran `sapply` over them to get the bounding boxes of each spatial object. That produced an output matrix `spdat_boxes`, to which I assigned rownames that give meaning to the bounding box values, specifically the westernmost (xmin), southernmost (ymin), easternmost (xmax), and northernmost (ymax) coordinates. 

The results show us that `roads`' coordinates are in different units (meters) than `districts`' and `farmers`' (both decimal degrees).  That means when we try to plot `roads` on the same map as the other two, the roads don't actually appear because the units are not the same. You can see the roads if you plot them on their own, which you should do so on your own [<span style="color:blue">Exercise 4</span><a name="exercise4"></a>]

We have seen this problem before with non-spatial data, specifically Task 12 in Unit 1's [assignment 3](#assignment3.html), where you were asked to plot a `loess` prediction line onto an xy scatter where "date" was the unit on the the x axis,  but the loess line was calculated against an integer vector. In that case, we had to change the x values against which we were plotting `loess`, which simply meant we had to "date" into the x argument for the `lines` function to get the `loess` line to appear on the plot. 

[Back to top](#vectorintro)

### Checking the CRS of a `Spatial*` object

In this case, we have to do a bit more, which is to convert `roads` coordinate reference system (crs) to decimal degrees.  How do we do that?  First, we have to know the crs we want to transform `roads` into, which we can do by checking the `proj4string` of `farmers` or `districts`.  Let's check this in two ways:

```{r}
districts@proj4string  # considered poor etiquette
proj4string(districts)  # good etiquete
```

The first approach uses the `@` operator, which is a method for extracting the information from a slot in an S4 object (see `?Syntax`), whereas you use the `$` operator to do the same for an S3 object. I put a comment there that suggests this is poor etiquette, because I have seen it said in places here and there over the years. The preferred method is the second one, where you are using a function designed to access and manipulate a specific slot, in this case `proj4string`. 

Both approaches return the projection string, which contains the projection parameters. If you want to understand the meaning of projection string parameters, please have a look at the [documentation](http://proj4.org) for the `proj.4` library, specifically the page on [parameters](http://proj4.org/parameters.html).

This one basically tells us that `districts` has a geographic (longlat) projection, and uses the WGS84 datum.  Let's check the crs for `farmers` now to see if it has the same crs

```{r, results='hold'}
sapply(spdat[c(1, 3)], function(x) proj4string(x))
# sapply(spdat[c("districts", "farmers")], function(x) proj4string(x))
```

I chose to do this programmatically in an `sapply`, in which the code demonstrates the use of recursive indexing to subset the list `spdat` (selecting the 1st and 3rd list elements, or, in the commented out alternative, doing the same with a vector of element names) and pass the subset into `sapply` (where the `proj4string` function is applied).

    
> An aside: In the example above, we subset a list using just a single set of brackets `[]`, not `[[]]`. You can select a single element from a list using either `[[]]` or `[]`, e.g. `spdat[1]` or `spdat[[1]]`, but you can't select multiple elements with `[[]]`. Test it yourself using the code below. 

> ```{r, eval = FALSE}
l <- list(1, 2, 3)
l[[1]]  # a vector
l[1]  # a list
l[[1:2]]  # fail
l[1:2]  # a list
```

The results from the last `sapply` code block show that `districts` has a projection string (or p4s, as shorthand "proj4string"), whereas `farmers` does not. Before we move to the next step, reprojecting, let's fix that.  

```{r, results='hold'}
proj4string(spdat$farmers) <- proj4string(spdat$districts)
proj4string(farmers) <- proj4string(districts)
proj4string(spdat$farmers)
proj4string(farmers)
```

Simple--we apply the fix to `farmers` and to `spdat$farmers` by assigning the p4s from `spdat$districts` (i.e. `districts`). We can do that because we are pretty sure that the coordinates for farmers are from a geographic coordinate system that uses the WGS84 datum. If that is incorrect, we are introducing some spatial error. But for now, this is fine. 

[Back to top](#vectorintro)

### Reprojecting with `spTransform`

Okay, so now we want to change `roads` to a GCS.  

```{r}
spdat$roads <- spTransform(x = spdat$roads, CRSobj = proj4string(districts))
```

We use `sp`'s `spTransform` function to reproject `spdat$roads` using the parameters supplied by `districts`' p4s, which is passed into the function via the "CRSobj" argument.  

And that's all. We can now redo our plots. I am going to show you two ways to do it. First, the straight forward way:

```{r, fig.align="center"}
par(mar = c(0, 0, 0, 0))
plot(spdat$districts, col = "grey")
lines(spdat$roads, col = "red")
points(spdat$farmers, pch = 20, col = "blue")

```

And a more programmatic way, since we have a list:
```{r, fig.align="center", results='hold'}
flist <- list(plot, lines, points)
cols <- c("grey", "red", "blue")
pchs <- c(0, 0, 20)
par(mar = c(0, 0, 0, 0))
# for(i in 1:length(spdat)) flist[[i]](spdat[[i]], col = cols[i], pch = pchs[i])
for(i in 1:length(spdat)) {
  flist[[i]](spdat[[i]], col = cols[i], pch = pchs[i])
}
```

First, you will notice that there are now roads in both maps, thanks to our reprojection of `spdat$roads`.  Second, you might ask "why are you showing us  that second approach to making the map?"

The answer doesn't relate to efficiency: I needed more lines of code in the second approach then the first (even excluded the commented out line). The purpose of this is two-fold: 

First, this show that you can combine ___functions___ into a list and iterate through them in a `for` loop, much as we iterate through different colors and pch symbols (only `points` really needed the "pch" argument, since that is the only function plotting points in this case, but passing 0 values to the other functions doesn't hurt).  

Secondly, there is a commented out line below `par`, which is there to demonstrate an alternative syntax for running the `for` loop. If you uncomment out that line, and comment out the active `for` loop, and re-run the code, you will see it works fine. What's more, the syntax is considered sylistically okay, since that particular line takes up less than 80 characters. If you use more than 80 characters on a line, it is better style to break the line. In the case of a `for` loop, that means going with the `{}` construction.  
 
Okay, one more way we could have done it. 
```{r, fig.align="center"}
adds <- c(FALSE, TRUE, TRUE)
par(mar = c(0, 0, 0, 0))
for(i in 1:length(spdat)) {
  plot(spdat[[i]], add = adds[i], col = cols[i], pch = pchs[i])
}
```

Note here that I am using `plot` function, which knows whether it is plotting polygons, lines, or points based on the spatial object it is applied to. Beyond the color and pch variables (recycled from above), we have a new variable `adds`, which has the logical values `FALSE`, `TRUE`, `TRUE`. We need that because the each repeated instance of `plot` will initiate a brand new plot, unless we pass the `TRUE` into the "add" argument, which means we want to add something to the plot we just made before it.  

Broken down, that looks like this: 

```{r, fig.align="center"}
par(mar = c(0, 0, 0, 0))
plot(spdat$districts, col = "grey")
plot(spdat$roads, add = TRUE, col = "red")
plot(spdat$farmers, add = TRUE, col = "blue", pch = 20)
```

Note the first plot doesn't have the add argument, because it creates the first plot and the "add" argument has the default value of `FALSE` set. The second and third plots need us to change the "add" to `TRUE` to plot on the same line. 

Right, that's the end of this section, but you are left with a final exercise to do [<span style="color:blue">Exercise 5</span><a name="exercise5"></a>]: 

1. Adapt the code above to reproject the spatial objects in `spdat` to the crs used by `roads`;

2. Recreate the same plots using this newly reprojected dataset (i.e. first plot the districts then add the roads and farmers to it. 

[Back to top](#vectorintro)

```{r, eval = FALSE, echo = FALSE}
# exercise 1
pts <- farmers[c("lon", "lat")]
coordinates(pts) <- ~lon + lat
class(pts)

# exercise 3
fnm <- system.file("extdata/districts.shp", package = "geospaar")
districts <- readOGR(dsn = fnm, layer = "districts")
class(districts)
class(roads)
str(districts)

# exercise 5
spdat2 <- sapply(spdat, function(x) {
  spTransform(x, proj4string(roads))
})
par(mar = c(0, 0, 0, 0))
plot(spdat2$districts, col = "grey")
plot(spdat2$roads, add = TRUE, col = "red")
plot(spdat2$farmers, add = TRUE, col = "blue", pch = 20)

```

# Section 2

In this section we are going to learn vector manipulations and operations, which will require the `rgeos` package. 

```{r, message=FALSE}
library(rgeos)
```

There are a total of X exercises: Exercises [#6](#exercise6), [#7](#exercise7), [#8](#exercise8), [#9](#exercise9), [#10](#exercise10)

## Extracting spatial properties

### Area

Using polygons to calculate area is a fairly basic but important spatial analytical operation. To calculate meaningful areas, you typically need your polygons to be in a projected coordinate system in which area is one of the true properties. The `roads` dataset has an Albers Equal Area projection that is suitable for this purpose, so let's apply it to reproject `districts` (as you would have done in [Exercise 5](#exercise5), and then extract areas for each district      

```{r, results='hold'}
districts_alb <- spTransform(districts, proj4string(roads))
districts_area <- gArea(spgeom = districts_alb)
districts_area  # sq meters
districts_area / 10000  # hectares
districts_area / 10^6  # km sq
```

We apply `rgeos::gArea` to the projected `districts_alb` dataset, which returns a single value in m$^2$, or alternatively in hectares or km$^2$, with some additional calculation. But that's for all of Zambia. What about for individual districts? For that, we simply set the "byid" argument to `TRUE`.

```{r, fig.align='center', fig.width=5, fig.height=3.5}
district_areas <- gArea(spgeom = districts_alb, byid = TRUE)
par(mar = c(5, 5, 3, 3))
hist(district_areas / 10000, main = "District Areas", xlab = "Hectares", 
     col = "grey")
```

Here we are showing the results as a histogram rather than printing out the numbers for each of the `r length(district_areas)` districts. 

There is also a second way of getting the area out of `SpatialPolygons*`, which is to access the "area" slot of each polygon. `SpatialPolygons*` objects store the area of each polygon as an attribute. The following shows how the `slot` function can be used to access the area value for the first polygon in `districts_alb`

```{r}
# districts_alb@polygons[[1]]@area / 1000  # get slots the non-recommended way
slot(slot(districts_alb, "polygons")[[1]], "area") / 10000  # recommended
```

That means we could access the area values for all 72 polygons programmatically, and then see how the areas for each polygon in the slots compare to the areas calculated using `gArea`. 
```{r, fig.align="center"}
district_areas2 <- sapply(1:72, function(x) {
  slot(slot(districts_alb, "polygons")[[x]], "area")
})
plot(district_areas2, district_areas)
```

See what we did there?  We iterated through each polygon in `districts_alb` and extract the area slot, and then plotted the results against the `gArea`-obtained results. They look the same, but won't necessarily always be the same. Read the "Value" section of `?gArea` to see why. 

### Distance

We can also calculate the distances between spatial features. To do that, we are going to make use of another `rgeos` function first, `gCentroid`, which we will use to find the coordinates of the centroid of each district, and then plot the on top of the districts themselves. 
```{r, fig.align='center'}
dist_cent <- gCentroid(spgeom = districts_alb, byid = TRUE)  # get centroids
head(dist_cent)

# plot centroids on districts
par(mar = c(0, 0, 0, 0))
plot(districts_alb, col = "grey")
points(dist_cent, col = "red", pch = 20)
```

The resulting centroids in `dist_cent` are of class `r class(dist_cent)`. Note the use of "byid = TRUE" as an argument.  If we set that to `FALSE`, or didn't specify the argument at all, it would have returned a single set of coordinates for the centroid of Zambia. Redo the code above so that you get just the centroid of Zambia, and then plot that onto the district map of Zambia (i.e. the map above, but with just one red point in Zambia' geographic center [<span style="color:blue">Exercise 6</span><a name="exercise6"></a>].

We can now find out how far apart the centroids of each district are by using another `rgeos` function, `gDistance`

```{r}
all_dists <- gDistance(spgeom1 = dist_cent, byid = TRUE)
d1_dists <- gDistance(spgeom1 = dist_cent[1, ], spgeom2 = dist_cent[-1, ],
                      byid = TRUE)
quantile(d1_dists / 1000)
```

There are two variants above. The first is captured in `all_dists`, and it produces a matrix that provides the distance, in meters, between each district centroid and every other district centroid. To get that, you simply pass in the entire `dist_cent` object to the "spgeom1" argument, and specify "byid = TRUE". The second variant (`d1_dists`), uses both "spgeom1" and "spgeom2" arguments, and it simply finds the distance between the first district centroid and all the other districts' centroids.

I invite you to examine the contents of both of those objects--I am not printing them here because this vignette is already long.  What I do show you is a summary of the distances in kilometers using the `quantile` function.

Okay, here's another exercise: figure out which district is the closest to the centroid of Zambia, and how far that distance is in kilometers [<span style="color:blue">Exercise 7</span><a name="exercise7"></a>]. 

### Length

For the last example of functions that extract spatial properties, we will use `gLength` to calculate line lengths.
```{r, fig.align='center', fig.width=7, fig.height=4}
road_lengths <- gLength(spgeom = roads, byid = TRUE)
district_perims <- gLength(spgeom = districts_alb, byid = TRUE)

par(mfrow = c(1, 2), mgp = c(3, 0.7, 0))
hist(road_lengths / 1000, xlab = "km", col = "blue", las = 2, cex.main = 0.8, 
     cex.lab = 0.8, cex.axis = 0.8, main = "Histogram of road lengths")
hist(district_perims / 1000, xlab = "km", col = "green4", las = 2,
     cex.main = 0.8, cex.lab = 0.8, cex.axis = 0.8, 
     main = "Histogram of district perimeters")
```

`gLength` applied to `SpatialLines*` gives us line lengths, and for `SpatialPolygons` it gives us perimeter length (including the perimeter around any holes in the polygons). If "byid = FALSE" (the default) in either case, you get total length (of all line segments or of all polygon perimeters).

The histograms plotted above have some graphical parameters added to them that might be new to you ("mgp", "cex.main", "cex.lab", "cex.axis"). ___I invite you to re-run the plots after changing the values passed to each argument so that you can understand what they do.___ 

[Back to top](#vectorintro)

## Manipulating `Spatial*DataFrames`

`Spatial*` objects in R can be manipulated using fairly similar methods as those used for manipulating non-spatial data structures. The code in the previous sections provides examples for how you subset by index numbers.  Another example:

```{r, fig.align="center"}
par(mar = c(0, 0, 0, 0))
plot(districts_alb, col = "grey")
plot(districts_alb[c(1, 20, 40), ], col = "blue", add = TRUE)
points(spTransform(farmers, proj4string(roads))[30:40, ], col = "red", pch = 20)
```

Notice that the sub-setting is done "on the fly" within the plotting functions themselves. The one applied to farmers follows the necessary reprojection step, which is also done on the fly. 

That's index-based subsetting. We can also do it using values stored within the rows and columns of the data. To do, we are first going to enhance those data a bit.  

[Back to top](#vectorintro)

### Merges

The previous examples have shown you how to calculate spatial properties and stick them in separate data objects. Now let's see how to add those properties to our `Spatial*DataFrame`s.  

We'll continue working with `districts_alb`, and start by adding the district areas to the `data.frame` of `districts_alb2`, a copy of `districts_alb`

```{r}
districts_alb2 <- districts_alb  # create a new version
districts_alb2$area <- gArea(districts_alb2, byid = TRUE)
# head(districts_alb@data)
head(slot(districts_alb2, "data"))
```

So that's a fairly straightforward way to do it. Just append the areas as a new column name on `districts_alb2` (which we create), which exactly the same way you would do it if this was just an ordinary `data.frame`. Note that this change only affects the `data.frame` part of `districts_alb`, and that to view the altered data.frame, you have to extract the `data.frame` from its slot.

We could also do the same thing this way
```{r}
districts_alb2 <- cbind(districts_alb, 
                        gArea(districts_alb, byid = TRUE))
colnames(districts_alb2@data) <- c("distName", "area")
head(slot(districts_alb2, "data"))
```

Or this way
```{r}
dist_area_df <- data.frame("distName" = districts_alb$distName, 
                           "area" = gArea(districts_alb, byid = TRUE))
districts_alb2 <- merge(districts_alb, dist_area_df, by.x = "distName", 
                        by.y = "distName")
head(slot(districts_alb2, "data"))
```

This last one might be new to you, as it uses the `merge` function. We had it in earlier readings, but didn't go over it much in class.  `merge` basically joins two `data.frame`s by the values in one or more columns that share the same values, or subsets of the same values. There is a `merge` method for ordinary `data.frame`s, and, as we see here, one for `Spatial*DataFrame`s. 

```{r, echo=FALSE, eval=FALSE}
# check merge ordering
set.seed(1)
n <- sample(1:length(districts_alb2), size = 7)
plot(districts_alb)
plot(districts_alb[n, ], add = TRUE, col = "red")
plot(districts_alb2[n, ], add = TRUE, col = "blue")
```

[Back to top](#vectorintro)

### Subsetting 

Now that we have upgraded the `data.frame` in `districts_alb2`, we can do some more subsetting. 

```{r, fig.align='center'}
dists_begkn <- districts_alb2[grep("^Ka|^Nyi", districts_alb2$distName), ]
dists_gt2M <- districts_alb2[districts_alb2$area / 10000 > 2000000, ]

par(mar = c(0, 0, 0, 0))
plot(districts_alb2, col = "grey")
plot(dists_begkn, col = rgb(0, 0, 1, alpha = 0.5), add = TRUE)
plot(dists_gt2M, col = rgb(1, 0, 0, alpha = 0.5), add = TRUE)

```

That's two examples of subsetting, in which the first (`dists_begkn`) selects districts with names beginning with either "Ka" or "Nyi", and the second (`dists_gt2M`) selects districts having areas greater than 2 million hectares (notice the division by 10000 to convert from m$^2$ to ha). 

The resulting subsets are plotted onto the full district map of Zambia. Note the use of the `rgb` function to define the colors used to fill the polygons. `rgb` makes red-green-blue color combinations, and the alpha argument allows you to define the transparency of the color.  In this case, our two subsets selected some of the same polygons (two of the districts with names beginning with "Ka" or "Ny" are also large than 2 million ha), so the partial transparency allows us to show where the overlaps occur. 

As an exercise, create new district subsets by use a different grep pattern match on the district names (look at `districts_alb2$distName` for some ideas), and by changing the area used as a threshold (e.g. make it 1 million ha) size, and the replot the results. Instead of a partially transparent blue, make a partially transparent green for the new `dists_gt2m`. [<span style="color:blue">Exercise 8</span><a name="exercise8"></a>] 

[Back to top](#vectorintro)

### Split-apply-combine

As with plain old `data.frame`s, we might want to do split-apply-combine operations on spatial data. Let's demonstrate this selecting the districts in `districts_alb2` that fall within certain area ranges, convert the selected districts to centroid points, and then plot them.  

```{r, fig.align='center'}
# define area ranges for smallest and largest districts
qt1090 <- quantile(districts_alb2$area, c(0.0, 0.05, 0.95, 1))
qt1090 <- rbind(qt1090[1:2], qt1090[3:4])  

# split-apply-combine
smlg_dist <- lapply(1:nrow(qt1090), function(x) {
  dists <- districts_alb2[districts_alb2$area >= qt1090[x, 1] & 
                            districts_alb2$area <= qt1090[x, 2], ]
  gCentroid(dists, byid = TRUE)
})

# plot, with legend
cols <- c("red", "blue")
par(mar = c(0, 0, 0, 0))
plot(districts_alb2, col = "grey")  # map background
for(i in 1:length(smlg_dist)) {
  points(smlg_dist[[i]], col = cols[i], pch = 20)
}
legend(x = "bottomright", pch = 20, col = cols, bty = "n",
       legend = c("Smallest districts", "Largest districts"))
```

That's pretty busy, so let me explain: 

- The first two lines use the `quantile` function to select the ranges of district areas within which the smallest 5% of districts and largest 5% of districts lie. It places these ranges within a matrix `qt1090`, where row 1 contains the minimum (column 1) and maximum (column 2) areas bounding the smallest 5% of areas, and row 2 does the same for the largest 5%.   

- The second block runs a split-apply-combine with `lapply`. The iteration occurs over the rows of `qt1090`, and the ___split___ is done by selecting the districts `districts_alb2` containing areas that fall within the ranges defined by the area values in the selected row of `qt1090`. `gCentroid` is then ___applied___ to the selected districts, which are combined into list `smlg_dist`. 

- The plot first sets up a base map of all the districts, then loops over `smlg_dist` and plots each set of points with a different color. New to this plot is the `legend` function. 


[Back to top](#vectorintro)

## Operations

Now we will move onto some of the common spatial operations that you can expect to do with polygons. To enable this, we are first going to create some additional spatial data. 

```{r, fig.align='center'}
# define data.frame of arbitrary x and y coordinates
coords <- data.frame("x" = c(25, 25.1, 26.3, 26.4, 26.3, 25.1), 
                     "y" = c(-15.5, -14.5, -14.6, -14.8, -15.6, -15.5))

# create SpatialPolygons
p <- Polygon(coords = coords)
ps <- Polygons(srl = list(p), ID = 1)
spp <- SpatialPolygons(Srl = list(ps))

# define GCS projection and transform to Albers 
proj4string(spp) <- proj4string(districts)
spp_alb <- spTransform(spp, proj4string(roads))

plot(districts_alb2, col = "grey")
plot(spp_alb, col = "purple", add = TRUE)
```

The above takes a `data.frame` of x and y coordinates, and builds it up through three steps into `SpatialPolygons`. Step 1 creates a single polygon `p` from the coordinates, step 2 combines that polygon into a polygon list with an ID value, and step3 turns the list of the list into `SpatialPolygons` (`spp`). We then define its crs and reproject it to Albers so we can plot out onto the map of Zambian districts. 

[Back to top](#vectorintro)

### Overlays/spatial queries

The first thing we will do with our made-up polygon is figure out the districts it intersects. 

```{r}
spp_alb_int <- over(x = spp_alb, y = districts_alb2, returnList = TRUE)
spp_alb_int
```

The `over` function returns the subset of `districts_alb2` that intersects with `spp_alb`, returning the relevant subset of `districts_alb2`'s data.frame within a list. 

Another way of figuring out the same answer is with a `rgeos` function, `gIntersects`

```{r}
spp_alb_int <- gIntersects(spgeom1 = spp_alb, spgeom2 = districts_alb2,
                           byid = TRUE)
head(spp_alb_int)
which(spp_alb_int)
```

So that gives somewhat different results. First, `gIntersects` returns a logical value, giving a `TRUE` or `FALSE` for each district in `districts_alb2` as to whether it is intersected by `spp_alb`. We can use the `which` operator to identify the index position of the districts that intersect, and then use the indices to subset out the matching districts.


[Back to top](#vectorintro)

### Intersects and Intersections

[Back to top](#vectorintro)

### Differences

[Back to top](#vectorintro)

### Unions

[Back to top](#vectorintro)


```{r, echo = FALSE, eval=FALSE}
# exercise 6
dist_cent <- gCentroid(spgeom = districts_alb)  # get centroids
plot(spTransform(districts, proj4string(roads)), col = "grey")
points(dist_cent, col = "red", pch = 20)

# exercse 7
zam_cent <- gCentroid(dist_cent)
zam_dists <- gDistance(spgeom1 = zam_cent, spgeom2 = dist_cent, byid = TRUE)
districts@data[which.min(zam_dists), ]
```














