---
title: "Unit 2 - Working with Raster Data"
author: "Lyndon Estes, Zhiwen Zhu"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    fig_caption: yes
    number_sections: yes
    toc_depth: 3
    toc: yes
vignette: >
  %\VignetteIndexEntry{Unit 2: Raster data}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

<style type="text/css">

body{ /* Normal  */
      font-size: 12px;
  }
td {  /* Table  */
  font-size: 12px;
}
h1.title {
  font-size: 38px;
  <!-- color: DarkRed; -->
}
h1 { /* Header 1 */
  font-size: 28px;
  <!-- color: DarkBlue; -->
}
h2 { /* Header 2 */
    font-size: 22px;
  <!-- color: DarkBlue; -->
}
h3 { /* Header 3 */
  font-size: 18px;
  <!-- font-family: "Times New Roman", Times, serif; -->
  <!-- color: DarkBlue; -->
}
code.r{ /* Code block */
    font-size: 12px;
}
pre { /* Code block - determines code spacing between lines */
    font-size: 14px;
}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align = 'center', fig.height = 4, 
                      fig.width = 5)
```

# Introduction{#rasterintro}

The preamble to this chapter is basically the same as for the chapter on [vector data](vector-data.html), except here we are working with rasters, and will primarily use the `raster` package (which we started using when working with vectors, because of the convenient functions). We will continue to draw on, directly or indirectly (via package dependencies), `sp`, `rgdal`, and `rgeos`.

One additional note. This unit deals almost entirely with the `raster` package and its associated classes. The `sp` package provides other methods for dealing with gridded data, but we are not going to cover those in this course because the `raster` package covers (I would argue) most gridded data use cases. I have been using R for nearly a decade, and rarely have the need to use non-`raster` classes to handle grids.  

> The material in this section assumes that the reader is familiar with standard GIS operations and concepts, ranging from projections and transformations to moving windows, raster algebra, terrain analysis, and the like. 
>
> As with the previous vector-focused materials, reading are designed with the expectation that you work through the code as you read through it, and do the exercises (as much as you can) before class. Additionally, you should also look at the help file for each new function that is introduced, in order to familiarize yourself with the arguments. 

[Back to top](#rasterintro)

# Preparation
## Working space

Please continue to use the same working space configuration as described in the [vector data](vector-data.html) vignette. 

## Installations

Let's start by loading the following packages.
```{r, warning=FALSE, message=FALSE}
library(geospaar)
library(rgdal)
library(rgeos)
library(raster)
```

# Section 1{#section1}

## Exercises{#unit1exercises} 
- [Exercise #1](#exercise1)
- [Exercise #2](#exercise2)
- [Exercise #3](#exercise3)
- [Exercise #4](#exercise4)
- [Exercise #5](#exercise5) 

## Data

We'll need the following data loaded in for this section
```{r, message=FALSE, warning=FALSE}
farmers <- read.csv(system.file("extdata/farmer_spatial.csv", 
                                package = "geospaar"), stringsAsFactors = FALSE)
roads <- readOGR(system.file("extdata/roads.shp", package = "geospaar"), 
                 layer = "roads", verbose = FALSE)
data("districts")
```

[Back to top](#rasterintro)

## Raster basics

### `RasterLayer`

We are going to start out by learning how to build our own `RasterLayer`.  

```{r}
e <- extent(c("xmin" = 27, "xmax" = 29, "ymin" = -16, "ymax" = -14))  # 1
r <- raster(x = e, res = 0.25, crs = crs(districts))  # 2 
set.seed(1)  
values(r) <- sample(1:100, size = ncell(r), replace = TRUE)  # 3
# r[] <- sample(1:100, size = ncell(r), replace = TRUE) 
# r <- setValues(x = r, values = sample(1:100, size = ncell(r), replace = TRUE))

par(mar = c(0, 0, 0, 4))
plot(districts, col = "grey")
plot(r, add = TRUE)
```

We just used several functions from the `raster` package to create a random `raster` named `r` that has a 1/4 degree resolution and covers an area of 2 X 2 degrees in southern Zambia. This particular raster is a temporary one that lives in memory. 

Let's walk through the labelled code. In # 1, we use `raster`'s `extent` function to define the boundaries of the raster, and then in # 2 use the `raster` function to create a raster from the resulting `r class(e)` object `e`, assigning a CRS using the "crs" argument, which in turn uses `raster`'s `crs` to extract the crs from `districts`. `crs` is similar to `sp::proj4string`, but outputs a different class of object. You can use the two functions somewhat interchangeably, however. The `raster` function can create a raster from many different types of input objects (passed to argument "x"), per `?raster`:

> filename (character), Extent, Raster*, SpatialPixels*, SpatialGrid*, object, 'image', matrix, im, or missing. Supported file types are the 'native' raster package format and those that can be read via rgdal

Line # 2 creates an empty raster `r` with no cell values, so in # 3 we assign some randomly selected values into `r`. Note the method of assignment, using the `values` function; there are two other lines commented out below # 3 that show different ways of doing the same job. 

The plot of `r` over `districts` uses the `plot` method defined for `raster*` objects. Note that it automatically creates a continuous legend. 

Let's look now at the structure of the object `r`.

```{r}
r
class(r)
typeof(r)
slotNames(r)
values(r)
# slot(slot(r, "data"), "values")  # identical to values(r)
res(r)
```

`r` is an S4 object that has fairly different slots compared to class `Spatial*`. We are not going to go into all of them, but it is useful to know the @file, @data, @extent, and @crs slots. @file itself holds a number of slots, but you should know the @file@name slot, which contains the file name and path for grids that that are read in from disk (it is empty in the case of `r`, since it is held in memory). @data contains many slots also, but the main one of interest is the @data@values slot, which can be accessed with the `values` function directly, or less directly using `slot` (both approaches are shown above). Interestingly, the resolution information is not stored in any of the slots of `r`, but rather calculated from the @extent and @ncols and @nrows slots by the `res` function.  

[Back to top](#rasterintro)

### `RasterStack` and `RasterBrick`

We have just seen how to create a `RasterLayer` and learned a bit about the structure of this kind of object, which is two-dimensional. We are now going to learn about three-dimensional rasters, which come in two flavors: `RasterStack` and `RasterBrick`. Before we proceed, we first need to create some new data. 

```{r}
r2 <- r > 50
r3 <- r
set.seed(1)
values(r3) <- rnorm(n = ncell(r3), mean = 10, sd = 2)
l <- list(r, r2, r3)
```

We used r to create two new rasters, `r2` and `r3`. `r2` was made by using a logical operator (`>`) to find the locations where `r`'s values exceed 50, creating a binary `raster` where 1 indicates the matching pixels, and 0 those that don't.  `r3` was made by using `r` as a template, then overwriting the values with numbers generated randomly from a normal distribution (`rnorm`).  These were then combined into list `l`. 

```{r}
s <- stack(l)
# s <- stack(r, r2, r3)  # also works
names(s) <- c("r", "r2", "r3")
s

b <- brick(s)
b

plot(b)
```

In the preceding code blocks, we use `l` to create a `RasterStack` and `RasterBrick`. These are very similar things, but have a few key differences. A `RasterStack` is a series of rasters that have the same extent and resolution, which are "stacked" on top of one another in the order that they are given in the input list. The stacked layers can from any number of files stored in different areas on disk. A `RasterBrick` does the same thing (stacks `RasterLayers` on top of one another), but is more restrictive because the layers, if read off disk, must be contained within a single file. This makes the `RasterBrick` less flexible than the `RasterStack`, but it has the advantage of faster processing times (according to `?brick`). 

Applying `plot` to a stack or brick results in the automatic plotting of each layer into its own sub-window, with coordinates along the plot axes.  

Time now for your first exercise: 

<span style="color:blue">Exercise 1</span><a name="exercise1"></a>: ___Create a new raster `r4`, using `r3` as a template. Update the values of `r` using numbers randomly selected from a uniform distribution ranging between 0 and 1 (this requires the `runif` function that we used back in Unit 1). Create another raster `r5` by finding the values greater than 0.5 in r4. Recreate the list `l` with `r`, `r2`, `r3`, `r4`, and `r5`, and then create and plot stack `s`___ ([Exercise index](#unit1exercises))

Let's end this section with a slightly more orderly and oriented way of plotting the layers in `s` (works for `b` also).

```{r, fig.width=7, fig.height=2.5}
par(mfrow = c(1, 3), mar = c(0, 0, 0, 4))
for(i in 1:nlayers(s)) {
  plot(districts, col = "grey")
  plot(s[[i]], add = TRUE)
}
```

### Reading and writing rasters

Our initial introduction has been working with `Raster*` data that are held in memory. Let's write these out onto disk and then read them back in. Write these to your "unit2/data" folder (see instructions in the [vector vignette](vector-data.html) for a refresher). 

```{r, eval = FALSE}
# Block 1 - write to disk
writeRaster(r, filename = "external/unit2/data/r.tif")
writeRaster(r2, filename = "external/unit2/data/r2.tif")
writeRaster(r3, filename = "external/unit2/data/r3.tif")
writeRaster(b, filename = "external/unit2/data/b.tif")

# Block 2 - read back in each individual raster and recreate stack
r <- raster("external/unit2/data/r.tif")
r2 <- raster("external/unit2/data/r2.tif")
r3 <- raster("external/unit2/data/r3.tif")
s <- stack(list(r, r2, r3))  # recreate stack

# Block 3 - programmatic creation of stack
fnms <- dir("external/unit2/data/", pattern = "r.*.tif", full.names = TRUE)
l <- lapply(fnms, function(x) raster(x))
s <- stack(l)

# Block 4 - read in brick
b <- raster("external/unit2/data/b.tif")  # incorrect
b <- brick("external/unit2/data/b.tif")  # correct
```

In Block 1 above, we use `writeRaster` to write out each of the three individual rasters to a geotiff, and write `b` to a three-band geotiff. In Block 2 we use the `raster` function to read back in the individual rasters, and then recreate stack `s` from those. Block 3 is a more programmatic way of executing Block 2, using the `dir` function to read the directory, looking for filenames matching a pattern, and returning the full paths to the matching files. These paths are then used in an `lapply` to read the files in with `raster`, recreating list `l`, which is then stacked. 

These last two blocks illustrate how `stack` can be used to create a three-dimensional grid from different files, which differ from what you see next in Block 4, where the "b.tif" is read back into a brick. You will see the comment there that suggests that the first line in block 4 is incorrect. Why is that? Answering that is part of the next exercise: 

<span style="color:blue">Exercise 2</span><a name="exercise2"></a>: 

___- Part 1: Why should you not use `raster` to read in a `brick`?___

___- Part 2: You can use the `brick` function to write to disk right when you first create the brick (by passing it the "filepath" argument with an output path and filename), rather than simply creating it as an object in memory. Your task is to create a new "b2.tif" on disk using the `brick` function, which you will apply to stack `s`___ ([Exercise index](#unit1exercises))

[Back to top](#rasterintro)

## From vector to raster and back again

Now that you know the major `Raster*` classes, and how to read and write them to disk, let's figure out how to change between raster and vector types. 

### Vector to raster
We have several vector datasets that come with `geospaar` which we can rasterize, starting with the district boundaries.   
```{r, fig.width=5, fig.height=4}
# Block 1
zamr <- raster(x = extent(districts), crs = crs(districts), res = 0.1)
values(zamr) <- 1:ncell(zamr)

# Block 2
districts$ID <- 1:length(districts)
distsr <- rasterize(x = districts, y = zamr, field = "ID")
distsr

par(mar = c(0, 0, 0, 4))
plot(distsr, axes = FALSE, box = FALSE)
```

In Block 1, we took an initial step to define a raster (`zamr`) that has the  properties of resolution (0.1 decimal degrees), CRS, and extent that we want our rasterized vector to have. We set the extent of this raster to that of `districts`, using `extent` to get the bounding box coordinates (`extent` retrieves the same parameters as `sp::bbox`, but the output is in a different format). 

In Block 2, we use `rasterize` to (as the name says) rasterize `districts`. The "y" argument is where we feed in `zamr`, the raster object that we are rasterizing `districts` against. The "field" argument supplies the column names of the values that we want rasterized. In this case, we created an "ID" variable to give an integer for each district name, as the district name cannot be written to the raster.   

Our plot removes the coordinate-labelled axes and box that is drawn around raster plots by default. 

Next we rasterize the `farmers` dataset, which requires a little more prep to be meaningful. 

```{r, fig.width=5, fig.height=4}
# Block 1
zamr2 <- raster(x = extent(districts), crs = crs(districts), res = 0.25)
values(zamr2) <- 1:ncell(zamr2)

# Block 2
farmers2 <- do.call(rbind, lapply(unique(farmers$uuid), function(x) {
  dat <- farmers[farmers$uuid == x, ][1, ]  # select first row only
}))
# farmers3 <- farmers[which(!duplicated(farmers$uuid)), ]
# nrow(farmers3) == nrow(farmers2)

# Block 3
coordinates(farmers2) <- ~lon + lat
farmers2$ct <- 1  # assign value of 1 to each farmers
farmersr <- rasterize(farmers2, zamr2, field = "ct", fun = sum)


par(mar = c(0, 0, 1, 4))
plot(gUnaryUnion(districts), col = "grey", border = "transparent", 
     main = "N farmers per 0.25 degree grid cell")
plot(farmersr, add = TRUE)
```

In Block 1, we create a coarser scale (0.25 degree) version of `zamr` (`zamr2`), because we want to rasterize a bit differently, in that we want the rasterization to produce a count of the number of farmers per grid cell. The previous resolution of 0.1 degrees is a bit too fine to convey the information nicely in a plot.  

In Block 2, we prep the data a bit more. Recall that `farmers` consists of weekly reporting data sent to us by a large number of farmers, which means that we have multiple reports sent by the same farmer (and thus repeated coordinates for each farmer). So we need to reduce `farmers` down to just one row for each individual farmer, so that we have just a single set of coordinates for each. We demonstrate this using two approachs. The first uses the now familiar split-apply-combine approach with `lapply`, in which the split is defined by the unique farmer IDs ("uuid"), and we then select the first row of the data at each split, thereby eliminating duplicated coordinates. This creates a new reduced-row `farmers2`. Commented out below that is the second approach, which is actually a much more efficient method that uses the `duplicated` function applied to `farmers$uuid`. Here's an exercise for you: 

<span style="color:blue">Exercise 3</span><a name="exercise3"></a>: ___Look up and explain the code used in those two commented-out lines, particularly what `duplicated` is doing, why there is an `!`  in front of it, and what the comparison if objects (with `==`) right below shows___ ([Exercise index](#unit1exercises))

In Block 3, we then do the rasterization. We first promote `farmers` to a spatial object, then assign a value of 1 to all rows in the new column "ct". We then rasterize, passing the `sum` function to the "fun" argument, which means that we end up with a count of the number of farmers falling within each 0.25 degree grid cell. 

The resulting plot shows that most cells have less than 20 farmers. 
 
You can also rasterize `SpatialLines*`, much as we did for points and polygons. However, `rasterize` is exceedingly slow on the `SpatialLines*` class, so we are not doing that here, but leaving commented out code to show how it could be done. 
```{r}
# Block 3 (not run because slow)
# roads$ID <- 1:length(roads)
# roads$length <- gLength(spgeom = roads, byid = TRUE) / 1000
# roadsgcs <- spTransform(roads[roads$length > 1000, ], crs(zamr))
# roadsr <- rasterize(x = roadsgcs, y = zamr, field = "ID", progress = "text")
```

[Back to top](#rasterintro)

### Raster to vector

`raster` gives us functions that allow us to transform rasters to vectors. 

```{r, fig.width=5, fig.height=4}
dists_fromr <- rasterToPolygons(x = distsr, dissolve = TRUE)
farmers_fromr <- rasterToPoints(x = farmersr, spatial = TRUE)

par(mar = c(0, 0, 0, 0))
plot(dists_fromr, col = topo.colors(n = length(districts)))
points(farmers_fromr, pch = 20, col = "red")
```

Vectorizing rasters and vectorizing back again means that you end up with lower  resolution vectors if the raster is fairly coarse. You will note that this has occurred here, both in converting the rasterized districts back to `SpatialPolygons*`, and the rasterized farmer counts back to points (note that different functions were used for both, but both retained the underlying cell values within the data slot of the output `Spatial` features).

How much does the degraded resolution affects statistics derived from the resulting spatial data. For instance, how much does the perimeter and area of `dists_fromr` differ from that of `districts`?  Answering that is your next exercise: 

<span style="color:blue">Exercise 4</span><a name="exercise4"></a>:
___Transform `dists_fromr` and `districts` into an Albers projection, and then calculate the overall perimeter and total area of each of the two objects. Then take the ratio of the results from both, e.g. [perimeter of project districts] / [perimeter of projected dists_fromr]. This will let us know how much the rasterizing impacted these two properties___ ([Exercise index](#unit1exercises))

[Back to top](#rasterintro)

## Projections

We have been working with our data in geographic coordinates systems up until now. Let's transform these to projected coordinates, using the rasterized districts as an example. 

```{r, fig.width=7, fig.height=2.5}
zamr_alb <- projectRaster(from = zamr, res = 11000, crs = crs(roads), 
                          method = "ngb")  # 1
distsr_alb <- projectRaster(from = distsr, to = zamr_alb, method = "ngb")  # 2

par(mfrow = c(1, 2), mar = c(0, 0, 0, 4))
plot(distsr, main = "GCS rasterized districts", axes = FALSE, box = FALSE)
plot(distsr_alb, main = "Albers rasterized districts", axes = FALSE, box = FALSE)
```

In our first step (# 1), we apply `projectRaster` to our `zamr` object, transforming it to the Albers projection used by `roads` (the "crs" argument). We define an output "res" of 11,000 m, or 11 km, which is reasonably close to the 1/10th of a degree resolution of `zamr`. We also choose a "method" for calculating the transformed values in the new raster. In this case, since `zamr` has values that are basically an integer index of grid cells, we use the "ngb" (nearest neighbor) option, to avoid the bilinear interpolation that would occur by default (see `?projectRaster`). 

The result, `zamr_alb`, then becomes a reference raster (i.e. the raster defining the parameters) for other rasters that need to be reprojected, which is how we use it when reprojecting `distsr_alb` (# 2). In this case, we pass `zamr_alb` to the "to" argument, and don't need the "res" or "crs" arguments (because those values are read by the function from "zamr_alb"). Here we again use the "ngb" method so that we do not change the values of the categorical identifier of each district (you can see what I mean in the plot below comparing the bilinear to ngb method--see how the bilinear approach changes values along district boundaries?)

```{r, fig.width=7, fig.height=2.5}
distsr_alb2 <- projectRaster(from = distsr, to = zamr_alb, method = "bilinear")

par(mfrow = c(1, 2), mar = c(0, 0, 0, 4))
plot(distsr_alb2, main = "Bilinear reprojection", axes = FALSE, box = FALSE)
plot(distsr_alb, main = "Nearest neighbor", axes = FALSE, box = FALSE)
```

A bilinear interpolation would be more appropriate with a continuous raster, or one where it makes sense to have values averaged during the reprojection process, such as the `farmersr` dataset. For your final exercise, you will reproject this dataset:

<span style="color:blue">Exercise 5</span><a name="exercise5"></a>:
___Reproject `farmersr` to Albers (i.e. use `crs(roads)`, but in this case you will need to rasterize at a different resolution, since `farmersr` was rasterized to 0.25 degrees (which is about 25 km, or 25,000 m). Reproject using the bilinear method___. ([Exercise index](#unit1exercises))

[Back to top](#rasterintro)

That's it for this reading! We'll pick up with a bit more raster processing work in the next section, before getting to raster analyes. 

# Section 2{#section2}

This unit starts to focus on some of the analyses you can do with raster data, which we will get into after doing a bit more on raster processing and preparation.  

## Data 

We will keep working with the data from the previous sections, adding in a new dataset that loads with `geospaar`, `chirps`

```{r}
data("chirps")
```

## Exercises{#unit2exercises} 
- [Exercise #6](#exercise6)
- [Exercise #7](#exercise7)
- [Exercise #8](#exercise8)
- [Exercise #9](#exercise9)
- [Exercise #10](#exercise10) 

## Raster processing, continued

There a few important things we missed doing in the first section. But first let's talk about the new data we just loaded, `chirps`. We have a help file in `geospaar` describing the dataset, which is provides daily rainfall values at ~5 km resolution, estimated from satellite observations (of cloud top temperature, I believe) and corrected by weather station observations. CHIRPS is a near global product that extends back to the 1970s (read more about it [here](http://chg.geog.ucsb.edu/data/chirps/)), but we have just subset 28 days of data over Zambia. 

```{r}
chirps
names(chirps)
```

That tells us a bit more about the `chirps` subset that we have, including the names we have given to each of the layers, which corresponds to a different in the time series, beginning with Y16299 (Y16 = 2016, 299 = julian day 299, or October 25th) and ending with Y16326 (11/22/2016). Let's have a look at a few of these days. 

```{r, fig.width=7, fig.height=2.5}
zam <- gUnaryUnion(districts)
par(mfrow = c(1, 3), mar = c(0, 0, 1, 4))
for(i in 1:3) {
  leg <- ifelse(test = i == 3, yes = TRUE, no = FALSE)  # 1
  plot(chirps[[i]], main = names(chirps)[[i]], axes = FALSE, box = FALSE, 
       zlim = c(0, max(chirps[1:3])), legend = leg)  # 2
  plot(zam, add = TRUE)
}
```

The above plots the first three dates in `chirps` and drapes Zambia's outline over it. These data are obviously not just confined to Zambia, so that sets up our next set of processing steps we need to consider.  First, please read the coding notes, because we have added new steps in here: 

> Coding notes: In the plotting code you will see two new things. The use of `ifelse`, a function that allows you to test a condition and assign a value that corresponds to the result of that test.  We use this to tell plot whether or not to add the legend to the figure panel being plotted.  Here we wanted just one legend, because I used the argument zlim within `plot`. This sets a limit on the range of data values that are plotted, which in this case for each plot falls between 0 and the maximum rainfall value observed across all three of the plotted dates.  That gives all three plots a common scale, and, given that, why junk up the plots with three legends showing the same thing?  

> Indexing note: It hasn't been said yet, but you will note from the example above that indexing into a `RasterStackBrick` to select a particular layer or layers is achieved through `[[]]`. This applies to both single (`[[x]]`) and multiple/recursive (`[[x:y]]`) indexing (the latter detail differs from indexing into a `list`, where you use `[x:y]` for multiple selection). Selection by layer names also works (`chirps[[c("Y16299", "Y16300")]]`; `chirps[["Y16299"]]`)

### Masking

We are interested in the data that fall within Zambia's borders, so we need to mask out the values from `chirps` that fall outside of Zambia. 

```{r, fig.width=5, fig.height=4}
test_m <- mask(x = chirps[[1]], mask = districts)
par(mar = c(0, 0, 0, 4))
plot(test_m, axes = FALSE, box = FALSE)  
```

In the code above, we use the `districts` data to mask out the portions of `chirps` (the first day in the time series only) falling outside of Zambia.  

Let's apply that to the entire `chirps` dataset
```{r, fig.width=7, fig.height=2.5}
chirpsz <- mask(x = chirps, mask = districts)

par(mfrow = c(1, 3), mar = c(0, 0, 1, 4))
set.seed(1)
for(i in sample(1:nlayers(chirpsz), size = 3, replace = FALSE)) {
  plot(chirpsz[[i]], axes = FALSE, box = FALSE, main = names(chirpsz)[[i]]) 
}
```

Now we have a rainfall dataset that is confined to Zambia's borders (`chirpsz`). The three plots are randomly selected from the layers of `chirpsz`, as a check to confirm that the masking was applied to all layers. 

<span style="color:blue">Exercise 6</span><a name="exercise6"></a>:
___Mask `farmersr` using `districts` and plot the district boundaries over the masked result, suppressing the axes and box around the plot___ ([Exercise index](#unit2exercises))

### Cropping

If we need to chop a raster down to a smaller region, we can `crop` it. `crop` uses the extent of another object to achieve this. 

```{r, fig.width=5, fig.height=4}
chirps1_dist72 <- crop(x = chirpsz[[1]], y = districts[72, ])

par(mar = c(0, 0, 0, 4))
plot(chirps1_dist72, axes = FALSE, box = FALSE)
plot(districts, add = TRUE)
text(districts, labels = districts$ID)
```

The above uses the extent of district 72 to crop the first layer of `chirpsz`. 

Cropping is important if we want to confine further analyses to a particular sub-region.  However, if we just want to focus our plot to a particular region, then we zoom a plot to that region using an extent object. 

```{r, fig.width=5, fig.height=4}
par(mar = c(0, 0, 0, 4))
plot(chirpsz[[1]], axes = FALSE, box = FALSE, ext = extent(districts[72, ]))
plot(districts, add = TRUE)
text(districts, labels = districts$ID)
```

#### A function-writing detour

As we write this, we find ourselves growing weary of repeatedly writing "axes = FALSE, box = FALSE" into the `plot` function, even with Rstudio's handy tab completion. This is the sort of case (repeated use of the same code) where a new function is called for.  

```{r, eval = FALSE}
# x <- chirpsz[[1]]; x <- 1:10
plot_noaxes <- function(x, axes = FALSE, box = FALSE, mar = c(0, 0, 1, 4), 
                        ...) {
  if(!class(x) %in% c("RasterLayer", "RasterStack", "RasterBrick", "Extent")) {
    stop("This function is intended for rasters only", call. = FALSE)
  }
  par(mar = mar)
  plot(x, axes = axes, box = axes, ...)
}
```

The function above (not run here, as it now comes built with `geospaar`) takes care of the axes and box problem by setting their default arguments to FALSE. It also sets the default plot margins to the ones we have mostly been using so far (leaves room on the right for the legend and at the top for a title). And it checks whether the object being passed to it belongs to one of the raster classes, failing if it doesn't. Otherwise, it retains all of the ohter functionality of `raster::plot`, as it has the "..." argument, meaning you can pass other eligible arguments to it. 

Let's see how it works
```{r}
plot_noaxes(chirpsz[[1]])
```

That will make plotting easier moving forward. 

### Aggregating/disaggregating

To change to resolution of a raster object, you can use `aggregate` to make a coarser resolution, or disaggregate to decrease the resolution. To make `chirpsz` match the 0.1 resolution of `distsr` (the rasterized districts), we do this:

```{r}
chirpsz1agg <- aggregate(x = chirpsz[[1]], fact = 2, fun=mean)
chirpsz1agg
```

We aggregate the first layer of `chirpsz` by a factor of 2 ("fact = 2"), taking the average of the aggregated pixels ("fun = mean"). Since the starting resolution was 0.05, doubling the pixel size takes it 0.1. I could have chosen to aggregate all layers, and I could have chosen a different aggregation function (e.g. `sum`, `max`).

To disaggregate, there are two options:
```{r}
chirpsz1km <- disaggregate(x = chirpsz[[1]], fact = 5)
# chirpsz1km <- disaggregate(x = chirpsz[[1]], fact = 5, method = "bilinear") 
chirpsz1km
```

The first option is the default one, which just breaks apart each pixel into the number of smaller new pixels specified by the factor, giving each new smaller pixel the same value as its larger parent. Here we specified a factor of 5, leading to an output resolution of 0.01 (~1 km), and thus 25 times the number of pixels as in the original chirpsz[[1]] (run `ncell(chirpsz1km) / ncell(chirpsz[[1]])` to see).

The second way (commented out), is to pass the "method = bilinear" argument, which interpolates during disaggregation. In this case, `disaggregate` does the job using the `resample` function, which we will see next.  

<span style="color:blue">Exercise 7</span><a name="exercise7"></a>:
___Crop `chirpsz[[1]]` using the extent of `districts[57, ]`, and disaggregate it to 0.01 resolution using both the default and bilinear methods. Plot the results side by side using `plot_noaxes`___ ([Exercise index](#unit2exercises))

### Resampling

Resampling is done for many reasons, but one particularly common way is as a final step following aggregation or disaggregation, in order to co-register the resulting grid to another one. 

```{r, error=TRUE}
chirps125 <- aggregate(x = chirpsz[[1]], fact = 5)  # no fun b/c default is mean
s <- stack(chirps125, farmersr)  # fails 

par(mar = c(1, 1, 1, 1))
plot(extent(chirps125), axes = FALSE, col = "blue")
plot(extent(farmersr), add = TRUE, col = "red")

```

After aggregating `chirpsz` layer 1, we try and fail to stack the result with `farmersr`, because (as the plots of extents show and warning tells) the two objects have different extents. So, another approach is needed. 

```{r}
farmersr_rs <- resample(x = farmersr, y = chirps125) 
s <- stack(chirps125, farmersr_rs)  
names(s) <- c("rain", "farmer_count")
plot_noaxes(s)
```

We resample `farmersr` to `chirps125rs`, since it has the smaller extent. We can then stack and perform subsequent analyses on both, e.g. finding areas where rainfall exceeded 1 mm and where there was more than 1 farmer

```{r}
plot(s$rain > 1 & s$farmer_count > 1)
# plot(chirps125 > 1 & farmersr > 1)
```

## Raster analyses

Let's move on now to some analyses with raster data. 

### Global statistics

The most basic thing to do is calculate a variety of summary statistics and graphics from the rasters. 

```{r}
cellStats(x = chirpsz[[1]], stat = "mean")  # for a single date
cellStats(x = chirpsz[[c(5, 7, 14)]], stat = "mean")
summary(chirpsz[[1:3]])
```

`cellStats` lets you calculate specific statistics from the cell values of a lone `RasterLayer`, or for just a single, multiple, or all layers in a `RasterStackBrick`. `summary` returns the quintile values and counts the number of `NA` or no data cells. Both functions by default remove NA values (which are in many if not most rasters), which is something that usually has to be specified when trying to apply these statistical functions to an ordinary vector, e.g. 

```{r}
v <- values(chirpsz[[1]])
mean(v) 
mean(v, na.rm = TRUE)
```

`v` is a vector of all of the values from the first layer in the rainfall brick, including its NA values. `mean` returns an `NA` if you don't tell the function to remove `NA` values first.  

> This is important to remember, because both spatial and non-spatial data often have missing values, so you will have to deal with them explicitly in many cases. 

Okay, here's a more programmatic way of using `cellStats`:

```{r}
# Block 1
rain_stats <- lapply(c("mean", "sum", "sd", "cv"), function(x) {
  cellStats(x = chirpsz, stat = x)
})
names(rain_stats) <- c("mean", "sum", "sd", "cv")

# Block 2
dates <- names(rain_stats[[1]])
dates <- as.Date(gsub("Y", "", dates), "%y%j")  # convert names to date vector

# Block 3
par(mfrow = c(2, 2), mar = c(4, 4, 2, 2))
for(i in 1:length(rain_stats)) {
  plot(x = dates, y = rain_stats[[i]], type = "l", xlab = "Date", 
       ylab = paste("Rain", names(rain_stats)[i]), col = "blue")
}
```

Block 1 leverages `lapply` to calculate 4 statistics over all dates in `chirpsz`, meaning that we get a time series for each statistic as calculated over all of Zambia. 

Block 2 is just converting the character vector that gives the name for each date into a vector of actual dates, using `gsub` to first replace the "Y" in each name, and then `as.Date` to parse the remaining numbers into an actual date. The "%y%j" construction tells `as.Date` which parts of the character string relate to which part of a date: %y = two digit year; %j = julian day; placed next to one another %y%j means these two elements are immediately adjacent to one another in the string. 

> Practice: Try `as.Date("10-11-2017", "%m-%d-%Y")`, `as.Date("10112017", "%m-%d-%Y")`, and `as.Date("10112017", "%m-%d-%Y")` to get a better sense of how that works. 

Block 3 plots the time series, using the `dates` vector to provide the x variable. 

> These results are actually quite interesting. The top two rows show fairly clearly the start of the rainy season (just after Nov 8), and the bottom two show two measures of variability, the standard deviation (SD) and coefficient of variation (CV, i.e. SD / mean). These two measures are effectively characterizing the spatial variability of rainfall across Zambia on each day--SD increases as the amount of rain increases (which is expected--SD is usually positively correlated with the mean), whereas CV declines as rainfall increases, indicating that a progressively larger area of the country receives rainfall, so there is less spatial variability. There is a big spike in CV on November 8, which corresponds with a drop in mean and total rainfall. However, that drop masks in mean/total masks the fact that there are a few small patches that received a decent amount of rainfall, thus leading to a high CV (see plot below).  

```{r, fig.width=5, fig.height=4}
plot_noaxes(chirpsz[[15]], main = paste("CV =", round(rain_stats$cv[15])))
```

Another way to summarize raster data is visually, using a histogram (raster has a generic of `hist` designed for rasters)
```{r, fig.width=7, fig.height=4}
par(mfrow = c(1, 3))
hist(chirpsz[[15:17]], col = "blue", xlab = "mm")
```

This variant plots a histogram per layer in the `Raster*` object (but we told it to plot 1 row, 3 columns).  

`freq` is another way to summarize a raster values that is similar to `hist` but without the automatic plot.
```{r}
f <- freq(chirpsz[[1]])
f
```

Here we apply `freq` to a dataset with continuous values, while this is probably best reserved for categorical rasters, but the results seems reasonable here 

### Local statistics

The previous gives us statistics calculated across the entire raster. These summaries, and other analuyses, can also be done locally.  

### Zonal

One way local statistics can be calculated is by defining zones, and summarizing statistics within those zones. 

```{r}
# zonemu <- zonal(x = chirpsz, z = distsr, fun = "mean")  # fail b/c extent
distsr_rs <- resample(x = distsr, y = chirpsz, method = "ngb")  # match extent
zonemu <- zonal(x = chirpsz, z = distsr_rs, fun = "mean")
head(zonemu)[, 1:5]
```

That creates a matrix (truncated here) of mean rainfall within each zone ( district), by date. 

#### `subs`

To map the zonal onto their zones, we need to use another function, `subs`.

```{r}
distr_rfmu <- subs(x = distsr_rs, y = data.frame(zonemu)[, 1:2], by = "zone")
plot_noaxes(distr_rfmu)
```

`subs` replaces the values in a raster with those in a `data.frame` containing a variable with common values to those in `subs` (in this case the district IDs). It can be slow-ish on big rasters. 

<span style="color:blue">Exercise 8</span><a name="exercise8"></a>:
___Use zonal stats on `farmersr_rs` to calculate the total number of farmers per district, and then map them onto the districts as we did above. Remember that `farmersr_rs` is a coarser resolution than `distsr_rs`, but aggregating the districts further would lose a lot information. Disaggregating is also problematic because it messes up the zonal stats. Better to first re-rasterise `farmers2` to the 0.1 resolution, using `distsr_rs` as the reference (to get the right extent) and then calculate and map zonal stats___ ([Exercise index](#unit2exercises))

### Focal




[Back to top](#rasterintro)

# Section 3{#section3}

[Back to top](#rasterintro)

<span style="color:blue">Exercise 1</span><a name="exercise15"></a>: ___
___ [Exercise index](#unit3exercises)















