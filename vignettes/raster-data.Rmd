---
title: "Unit 2 - Working with Raster Data"
author: "Lyndon Estes, Zhiwen Zhu"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    fig_caption: yes
    number_sections: yes
    toc_depth: 3
    toc: yes
vignette: >
  %\VignetteIndexEntry{Unit 2: Raster data}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

<style type="text/css">

body{ /* Normal  */
      font-size: 12px;
  }
td {  /* Table  */
  font-size: 12px;
}
h1.title {
  font-size: 38px;
  <!-- color: DarkRed; -->
}
h1 { /* Header 1 */
  font-size: 28px;
  <!-- color: DarkBlue; -->
}
h2 { /* Header 2 */
    font-size: 22px;
  <!-- color: DarkBlue; -->
}
h3 { /* Header 3 */
  font-size: 18px;
  <!-- font-family: "Times New Roman", Times, serif; -->
  <!-- color: DarkBlue; -->
}
code.r{ /* Code block */
    font-size: 12px;
}
pre { /* Code block - determines code spacing between lines */
    font-size: 14px;
}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align = 'center', fig.height = 4, 
                      fig.width = 5)
```

# Introduction{#rasterintro}

The preamble to this chapter is basically the same as for the chapter on [vector data](vector-data.html), except here we are working with rasters, and will primarily use the `raster` package (which we started using when working with vectors, because of the convenient functions). We will continue to draw on, directly or indirectly (via package dependencies), `sp`, `rgdal`, and `rgeos`.

One additional note. This unit deals almost entirely with the `raster` package and its associated classes. The `sp` package provides other methods for dealing with gridded data, but we are not going to cover those in this course because the `raster` package covers (I would argue) most gridded data use cases. I have been using R for nearly a decade, and rarely have the need to use non-`raster` classes to handle grids.  

> The material in this section assumes that the reader is familiar with standard GIS operations and concepts, ranging from projections and transformations to moving windows, raster algebra, terrain analysis, and the like. 
>
> As with the previous vector-focused materials, reading are designed with the expectation that you work through the code as you read through it, and do the exercises (as much as you can) before class. Additionally, you should also look at the help file for each new function that is introduced, in order to familiarize yourself with the arguments. 

[Back to top](#rasterintro)

# Preparation
## Working space

Please continue to use the same working space configuration as described in the [vector data](vector-data.html) vignette. 

## Installations

Let's start by loading the following packages.
```{r, warning=FALSE, message=FALSE}
library(geospaar)
library(rgdal)
library(rgeos)
library(raster)
```

# Section 1{#section1}

## Exercises{#unit1exercises} 
- [Exercise #1](#exercise1)
- [Exercise #2](#exercise2)
- [Exercise #3](#exercise3)
- [Exercise #4](#exercise4)
- [Exercise #5](#exercise5) 

## Data

We'll need the following data loaded in for this section
```{r, message=FALSE, warning=FALSE}
farmers <- read.csv(system.file("extdata/farmer_spatial.csv", 
                                package = "geospaar"), stringsAsFactors = FALSE)
roads <- readOGR(system.file("extdata/roads.shp", package = "geospaar"), 
                 layer = "roads", verbose = FALSE)
data("districts")
```

[Back to top](#rasterintro)

## Raster basics

### `RasterLayer`

We are going to start out by learning how to build our own `RasterLayer`.  

```{r}
e <- extent(c("xmin" = 27, "xmax" = 29, "ymin" = -16, "ymax" = -14))  # 1
r <- raster(x = e, res = 0.25, crs = crs(districts))  # 2 
set.seed(1)  
values(r) <- sample(1:100, size = ncell(r), replace = TRUE)  # 3
# r[] <- sample(1:100, size = ncell(r), replace = TRUE) 
# r <- setValues(x = r, values = sample(1:100, size = ncell(r), replace = TRUE))

par(mar = c(0, 0, 0, 4))
plot(districts, col = "grey")
plot(r, add = TRUE)
```

We just used several functions from the `raster` package to create a random `raster` named `r` that has a 1/4 degree resolution and covers an area of 2 X 2 degrees in southern Zambia. This particular raster is a temporary one that lives in memory. 

Let's walk through the labelled code. In # 1, we use `raster`'s `extent` function to define the boundaries of the raster, and then in # 2 use the `raster` function to create a raster from the resulting `r class(e)` object `e`, assigning a CRS using the "crs" argument, which in turn uses `raster`'s `crs` to extract the crs from `districts`. `crs` is similar to `sp::proj4string`, but outputs a different class of object. You can use the two functions somewhat interchangeably, however. The `raster` function can create a raster from many different types of input objects (passed to argument "x"), per `?raster`:

> filename (character), Extent, Raster*, SpatialPixels*, SpatialGrid*, object, 'image', matrix, im, or missing. Supported file types are the 'native' raster package format and those that can be read via rgdal

Line # 2 creates an empty raster `r` with no cell values, so in # 3 we assign some randomly selected values into `r`. Note the method of assignment, using the `values` function; there are two other lines commented out below # 3 that show different ways of doing the same job. 

The plot of `r` over `districts` uses the `plot` method defined for `raster*` objects. Note that it automatically creates a continuous legend. 

Let's look now at the structure of the object `r`.

```{r}
r
class(r)
typeof(r)
slotNames(r)
values(r)
# slot(slot(r, "data"), "values")  # identical to values(r)
res(r)
```

`r` is an S4 object that has fairly different slots compared to class `Spatial*`. We are not going to go into all of them, but it is useful to know the @file, @data, @extent, and @crs slots. @file itself holds a number of slots, but you should know the @file@name slot, which contains the file name and path for grids that that are read in from disk (it is empty in the case of `r`, since it is held in memory). @data contains many slots also, but the main one of interest is the @data@values slot, which can be accessed with the `values` function directly, or less directly using `slot` (both approaches are shown above). Interestingly, the resolution information is not stored in any of the slots of `r`, but rather calculated from the @extent and @ncols and @nrows slots by the `res` function.  

[Back to top](#rasterintro)

### `RasterStack` and `RasterBrick`

We have just seen how to create a `RasterLayer` and learned a bit about the structure of this kind of object, which is two-dimensional. We are now going to learn about three-dimensional rasters, which come in two flavors: `RasterStack` and `RasterBrick`. Before we proceed, we first need to create some new data. 

```{r}
r2 <- r > 50
r3 <- r
set.seed(1)
values(r3) <- rnorm(n = ncell(r3), mean = 10, sd = 2)
l <- list(r, r2, r3)
```

We used r to create two new rasters, `r2` and `r3`. `r2` was made by using a logical operator (`>`) to find the locations where `r`'s values exceed 50, creating a binary `raster` where 1 indicates the matching pixels, and 0 those that don't.  `r3` was made by using `r` as a template, then overwriting the values with numbers generated randomly from a normal distribution (`rnorm`).  These were then combined into list `l`. 

```{r}
s <- stack(l)
# s <- stack(r, r2, r3)  # also works
names(s) <- c("r", "r2", "r3")
s

b <- brick(s)
b

plot(b)
```

In the preceding code blocks, we use `l` to create a `RasterStack` and `RasterBrick`. These are very similar things, but have a few key differences. A `RasterStack` is a series of rasters that have the same extent and resolution, which are "stacked" on top of one another in the order that they are given in the input list. The stacked layers can from any number of files stored in different areas on disk. A `RasterBrick` does the same thing (stacks `RasterLayers` on top of one another), but is more restrictive because the layers, if read off disk, must be contained within a single file. This makes the `RasterBrick` less flexible than the `RasterStack`, but it has the advantage of faster processing times (according to `?brick`). 

Applying `plot` to a stack or brick results in the automatic plotting of each layer into its own sub-window, with coordinates along the plot axes.  

Time now for your first exercise: 

<span style="color:blue">Exercise 1</span><a name="exercise1"></a>: ___Create a new raster `r4`, using `r3` as a template. Update the values of `r` using numbers randomly selected from a uniform distribution ranging between 0 and 1 (this requires the `runif` function that we used back in Unit 1). Create another raster `r5` by finding the values greater than 0.5 in r4. Recreate the list `l` with `r`, `r2`, `r3`, `r4`, and `r5`, and then create and plot stack `s`___ ([Exercise index](#unit1exercises))

Let's end this section with a slightly more orderly and oriented way of plotting the layers in `s` (works for `b` also).

```{r, fig.width=7, fig.height=2.5}
par(mfrow = c(1, 3), mar = c(0, 0, 0, 4))
for(i in 1:nlayers(s)) {
  plot(districts, col = "grey")
  plot(s[[i]], add = TRUE)
}
```

[Back to top](#rasterintro)

### Reading and writing rasters

Our initial introduction has been working with `Raster*` data that are held in memory. Let's write these out onto disk and then read them back in. Write these to your "unit2/data" folder (see instructions in the [vector vignette](vector-data.html) for a refresher). 

```{r, eval = FALSE}
# Block 1 - write to disk
writeRaster(r, filename = "external/unit2/data/r.tif")
writeRaster(r2, filename = "external/unit2/data/r2.tif")
writeRaster(r3, filename = "external/unit2/data/r3.tif")
writeRaster(b, filename = "external/unit2/data/b.tif")

# Block 2 - read back in each individual raster and recreate stack
r <- raster("external/unit2/data/r.tif")
r2 <- raster("external/unit2/data/r2.tif")
r3 <- raster("external/unit2/data/r3.tif")
s <- stack(list(r, r2, r3))  # recreate stack

# Block 3 - programmatic creation of stack
fnms <- dir("external/unit2/data/", pattern = "r.*.tif", full.names = TRUE)
l <- lapply(fnms, function(x) raster(x))
s <- stack(l)

# Block 4 - read in brick
b <- raster("external/unit2/data/b.tif")  # incorrect
b <- brick("external/unit2/data/b.tif")  # correct
```

In Block 1 above, we use `writeRaster` to write out each of the three individual rasters to a geotiff, and write `b` to a three-band geotiff. In Block 2 we use the `raster` function to read back in the individual rasters, and then recreate stack `s` from those. Block 3 is a more programmatic way of executing Block 2, using the `dir` function to read the directory, looking for filenames matching a pattern, and returning the full paths to the matching files. These paths are then used in an `lapply` to read the files in with `raster`, recreating list `l`, which is then stacked. 

These last two blocks illustrate how `stack` can be used to create a three-dimensional grid from different files, which differ from what you see next in Block 4, where the "b.tif" is read back into a brick. You will see the comment there that suggests that the first line in block 4 is incorrect. Why is that? Answering that is part of the next exercise: 

<span style="color:blue">Exercise 2</span><a name="exercise2"></a>: 

___- Part 1: Why should you not use `raster` to read in a `brick`?___

___- Part 2: You can use the `brick` function to write to disk right when you first create the brick (by passing it the "filepath" argument with an output path and filename), rather than simply creating it as an object in memory. Your task is to create a new "b2.tif" on disk using the `brick` function, which you will apply to stack `s`___ ([Exercise index](#unit1exercises))

[Back to top](#rasterintro)

## From vector to raster and back again

Now that you know the major `Raster*` classes, and how to read and write them to disk, let's figure out how to change between raster and vector types. 

### Vector to raster
We have several vector datasets that come with `geospaar` which we can rasterize, starting with the district boundaries.   
```{r, fig.width=5, fig.height=4}
# Block 1
zamr <- raster(x = extent(districts), crs = crs(districts), res = 0.1)
values(zamr) <- 1:ncell(zamr)

# Block 2
districts$ID <- 1:length(districts)
distsr <- rasterize(x = districts, y = zamr, field = "ID")
distsr

par(mar = c(0, 0, 0, 4))
plot(distsr, axes = FALSE, box = FALSE)
```

In Block 1, we took an initial step to define a raster (`zamr`) that has the  properties of resolution (0.1 decimal degrees), CRS, and extent that we want our rasterized vector to have. We set the extent of this raster to that of `districts`, using `extent` to get the bounding box coordinates (`extent` retrieves the same parameters as `sp::bbox`, but the output is in a different format). 

In Block 2, we use `rasterize` to (as the name says) rasterize `districts`. The "y" argument is where we feed in `zamr`, the raster object that we are rasterizing `districts` against. The "field" argument supplies the column names of the values that we want rasterized. In this case, we created an "ID" variable to give an integer for each district name, as the district name cannot be written to the raster.   

Our plot removes the coordinate-labelled axes and box that is drawn around raster plots by default. 

Next we rasterize the `farmers` dataset, which requires a little more prep to be meaningful. 

```{r, fig.width=5, fig.height=4}
# Block 1
zamr2 <- raster(x = extent(districts), crs = crs(districts), res = 0.25)
values(zamr2) <- 1:ncell(zamr2)

# Block 2
farmers2 <- do.call(rbind, lapply(unique(farmers$uuid), function(x) {
  dat <- farmers[farmers$uuid == x, ][1, ]  # select first row only
}))
# farmers3 <- farmers[which(!duplicated(farmers$uuid)), ]
# nrow(farmers3) == nrow(farmers2)

# Block 3
coordinates(farmers2) <- ~lon + lat
farmers2$ct <- 1  # assign value of 1 to each farmers
farmersr <- rasterize(farmers2, zamr2, field = "ct", fun = sum)


par(mar = c(0, 0, 1, 4))
plot(gUnaryUnion(districts), col = "grey", border = "transparent", 
     main = "N farmers per 0.25 degree grid cell")
plot(farmersr, add = TRUE)
```

In Block 1, we create a coarser scale (0.25 degree) version of `zamr` (`zamr2`), because we want to rasterize a bit differently, in that we want the rasterization to produce a count of the number of farmers per grid cell. The previous resolution of 0.1 degrees is a bit too fine to convey the information nicely in a plot.  

In Block 2, we prep the data a bit more. Recall that `farmers` consists of weekly reporting data sent to us by a large number of farmers, which means that we have multiple reports sent by the same farmer (and thus repeated coordinates for each farmer). So we need to reduce `farmers` down to just one row for each individual farmer, so that we have just a single set of coordinates for each. We demonstrate this using two approachs. The first uses the now familiar split-apply-combine approach with `lapply`, in which the split is defined by the unique farmer IDs ("uuid"), and we then select the first row of the data at each split, thereby eliminating duplicated coordinates. This creates a new reduced-row `farmers2`. Commented out below that is the second approach, which is actually a much more efficient method that uses the `duplicated` function applied to `farmers$uuid`. Here's an exercise for you: 

<span style="color:blue">Exercise 3</span><a name="exercise3"></a>: ___Look up and explain the code used in those two commented-out lines, particularly what `duplicated` is doing, why there is an `!`  in front of it, and what the comparison if objects (with `==`) right below shows___ ([Exercise index](#unit1exercises))

In Block 3, we then do the rasterization. We first promote `farmers` to a spatial object, then assign a value of 1 to all rows in the new column "ct". We then rasterize, passing the `sum` function to the "fun" argument, which means that we end up with a count of the number of farmers falling within each 0.25 degree grid cell. 

The resulting plot shows that most cells have less than 20 farmers. 
 
You can also rasterize `SpatialLines*`, much as we did for points and polygons. However, `rasterize` is exceedingly slow on the `SpatialLines*` class, so we are not doing that here, but leaving commented out code to show how it could be done. 
```{r}
# Block 3 (not run because slow)
# roads$ID <- 1:length(roads)
# roads$length <- gLength(spgeom = roads, byid = TRUE) / 1000
# roadsgcs <- spTransform(roads[roads$length > 1000, ], crs(zamr))
# roadsr <- rasterize(x = roadsgcs, y = zamr, field = "ID", progress = "text")
```

[Back to top](#rasterintro)

### Raster to vector

`raster` gives us functions that allow us to transform rasters to vectors. 

```{r, fig.width=5, fig.height=4}
dists_fromr <- rasterToPolygons(x = distsr, dissolve = TRUE)
farmers_fromr <- rasterToPoints(x = farmersr, spatial = TRUE)

par(mar = c(0, 0, 0, 0))
plot(dists_fromr, col = topo.colors(n = length(districts)))
points(farmers_fromr, pch = 20, col = "red")
```

Vectorizing rasters and vectorizing back again means that you end up with lower  resolution vectors if the raster is fairly coarse. You will note that this has occurred here, both in converting the rasterized districts back to `SpatialPolygons*`, and the rasterized farmer counts back to points (note that different functions were used for both, but both retained the underlying cell values within the data slot of the output `Spatial` features).

How much does the degraded resolution affects statistics derived from the resulting spatial data. For instance, how much does the perimeter and area of `dists_fromr` differ from that of `districts`?  Answering that is your next exercise: 

<span style="color:blue">Exercise 4</span><a name="exercise4"></a>:
___Transform `dists_fromr` and `districts` into an Albers projection, and then calculate the overall perimeter and total area of each of the two objects. Then take the ratio of the results from both, e.g. [perimeter of project districts] / [perimeter of projected dists_fromr]. This will let us know how much the rasterizing impacted these two properties___ ([Exercise index](#unit1exercises))

[Back to top](#rasterintro)

## Projections

We have been working with our data in geographic coordinates systems up until now. Let's transform these to projected coordinates, using the rasterized districts as an example. 

```{r, fig.width=7, fig.height=2.5}
zamr_alb <- projectRaster(from = zamr, res = 11000, crs = crs(roads), 
                          method = "ngb")  # 1
distsr_alb <- projectRaster(from = distsr, to = zamr_alb, method = "ngb")  # 2

par(mfrow = c(1, 2), mar = c(0, 0, 0, 4))
plot(distsr, main = "GCS rasterized districts", axes = FALSE, box = FALSE)
plot(distsr_alb, main = "Albers rasterized districts", axes = FALSE, box = FALSE)
```

In our first step (# 1), we apply `projectRaster` to our `zamr` object, transforming it to the Albers projection used by `roads` (the "crs" argument). We define an output "res" of 11,000 m, or 11 km, which is reasonably close to the 1/10th of a degree resolution of `zamr`. We also choose a "method" for calculating the transformed values in the new raster. In this case, since `zamr` has values that are basically an integer index of grid cells, we use the "ngb" (nearest neighbor) option, to avoid the bilinear interpolation that would occur by default (see `?projectRaster`). 

The result, `zamr_alb`, then becomes a reference raster (i.e. the raster defining the parameters) for other rasters that need to be reprojected, which is how we use it when reprojecting `distsr_alb` (# 2). In this case, we pass `zamr_alb` to the "to" argument, and don't need the "res" or "crs" arguments (because those values are read by the function from "zamr_alb"). Here we again use the "ngb" method so that we do not change the values of the categorical identifier of each district (you can see what I mean in the plot below comparing the bilinear to ngb method--see how the bilinear approach changes values along district boundaries?)

```{r, fig.width=7, fig.height=2.5}
distsr_alb2 <- projectRaster(from = distsr, to = zamr_alb, method = "bilinear")

par(mfrow = c(1, 2), mar = c(0, 0, 0, 4))
plot(distsr_alb2, main = "Bilinear reprojection", axes = FALSE, box = FALSE)
plot(distsr_alb, main = "Nearest neighbor", axes = FALSE, box = FALSE)
```

A bilinear interpolation would be more appropriate with a continuous raster, or one where it makes sense to have values averaged during the reprojection process, such as the `farmersr` dataset. For your final exercise, you will reproject this dataset:

<span style="color:blue">Exercise 5</span><a name="exercise5"></a>:
___Reproject `farmersr` to Albers (i.e. use `crs(roads)`, but in this case you will need to rasterize at a different resolution, since `farmersr` was rasterized to 0.25 degrees (which is about 25 km, or 25,000 m). Reproject using the bilinear method___. ([Exercise index](#unit1exercises))

[Back to top](#rasterintro)

That's it for this reading! We'll pick up with a bit more raster processing work in the next section, before getting to raster analyes. 

# Section 2{#section2}

This unit starts to focus on some of the analyses you can do with raster data, which we will get into after doing a bit more on raster processing and preparation.  

## Data 

We will keep working with the data from the previous sections, adding in a new dataset that loads with `geospaar`, `chirps`

```{r}
data("chirps")
```

## Exercises{#unit2exercises} 
- [Exercise #6](#exercise6)
- [Exercise #7](#exercise7)
- [Exercise #8](#exercise8)
- [Exercise #9](#exercise9)
- [Exercise #10](#exercise10) 

## Raster processing, continued

There a few important things we missed doing in the first section. But first let's talk about the new data we just loaded, `chirps`. We have a help file in `geospaar` describing the dataset, which provides daily rainfall values at ~5 km resolution, estimated from satellite observations (of cloud top temperature, I believe) and corrected by weather station observations. CHIRPS is a near global product that extends back to the 1970s (read more about it [here](http://chg.geog.ucsb.edu/data/chirps/)), but we have just subset 28 days of data over Zambia. 

```{r}
chirps
names(chirps)
```

That tells us a bit more about the `chirps` subset that we have, including the names we have given to each of the layers, which correspond to the particular day in the rainfall time series, beginning with Y16299 (Y16 = 2016, 299 = julian day 299, or October 25th) and ending with Y16326 (11/22/2016). Note that `chirps` is actually a `RasterBrick` that we have saved as an .rda file that installs with `geospaar` for convenience. 

Let's have a look at a few of the days in `chirps`: 

```{r, fig.width=7, fig.height=2.5}
zam <- gUnaryUnion(districts)
par(mfrow = c(1, 3), mar = c(0, 0, 1, 4))
for(i in 1:3) {
  leg <- ifelse(test = i == 3, yes = TRUE, no = FALSE)  # 1
  plot(chirps[[i]], main = names(chirps)[[i]], axes = FALSE, box = FALSE, 
       zlim = c(0, max(chirps[1:3])), legend = leg)  # 2
  plot(zam, add = TRUE)
}
```

The above plots the first three dates in `chirps` and drapes Zambia's outline over it. These data are obviously not just confined to Zambia, so that sets up our next set of processing steps we need to do.  First, please read the coding following notes, because we have added new steps in here: 

> Coding notes: In the plotting code you will see two new things. The use of `ifelse`, a function that allows you to test a condition and assign a value that corresponds to the result of that test.  We use this to tell `plot` whether or not to add the legend to the figure panel being plotted.  Here we wanted just one legend, because I used the argument "zlim" within `plot`. This sets a limit on the range of data values that are plotted, which in this case for falls between 0 and the maximum rainfall value observed across all three of the plotted dates.  That gives all three plots a common scale, and, given that, why clutter up the plots with three legends showing the same thing?  

> Indexing note: It hasn't been said yet, but you will see in the example above that indexing into a `RasterStackBrick` to select a particular layer or layers is achieved through `[[]]`. This applies to both single (`[[x]]`) and multiple/recursive (`[[x:y]]`) indexing (the latter detail differs from indexing into a `list`, where you use `[x:y]` for multiple selection). Selection by layer names also works (`chirps[[c("Y16299", "Y16300")]]`; `chirps[["Y16299"]]`)

[Back to top](#rasterintro)

### Masking

We are interested in the data that fall within Zambia's borders, so we need to mask out the values from `chirps` that fall outside of Zambia. 

```{r, fig.width=5, fig.height=4}
test_m <- mask(x = chirps[[1]], mask = districts)
par(mar = c(0, 0, 0, 4))
plot(test_m, axes = FALSE, box = FALSE)  
```

In the code above, we use the `districts` data to mask out the portions of `chirps` (the first day in the time series only) falling outside of Zambia.  

Let's apply that to the entire `chirps` dataset
```{r, fig.width=7, fig.height=2.5}
chirpsz <- mask(x = chirps, mask = districts)

par(mfrow = c(1, 3), mar = c(0, 0, 1, 4))
set.seed(1)
for(i in sample(1:nlayers(chirpsz), size = 3, replace = FALSE)) {
  plot(chirpsz[[i]], axes = FALSE, box = FALSE, main = names(chirpsz)[[i]]) 
}
```

The new `chirpsz` dataset contains all rainfall days with the values outside of Zambia converted to NA. The three plots are randomly selected from the layers of `chirpsz`, as a check to confirm that the masking was applied to all layers. 

<span style="color:blue">Exercise 6</span><a name="exercise6"></a>:
___Mask `farmersr` using `districts`, and plot the district boundaries over the masked result, suppressing the axes and box around the plot___ ([Exercise index](#unit2exercises))

[Back to top](#rasterintro)

### Cropping

If we need to chop a raster down to a smaller region, we can `crop` it. `crop` uses the extent of another object to achieve this. 

```{r, fig.width=5, fig.height=4}
chirps1_dist72 <- crop(x = chirpsz[[1]], y = districts[72, ])

par(mar = c(0, 0, 0, 4))
plot(chirps1_dist72, axes = FALSE, box = FALSE)
plot(districts, add = TRUE)
text(districts, labels = districts$ID)
```

The above uses the extent of district 72 to crop the first layer of `chirpsz`. 

Cropping is important if we want to confine further analyses to a particular sub-region.  However, if we just want to focus our plot to a particular region, then we can simply zoom the plot to that region (without cropping) using an extent object. 

```{r, fig.width=5, fig.height=4}
par(mar = c(0, 0, 0, 4))
plot(chirpsz[[1]], axes = FALSE, box = FALSE, ext = extent(districts[72, ]))
plot(districts, add = TRUE)
text(districts, labels = districts$ID)
```

#### A function-writing detour

As we write this, we find ourselves growing weary of repeatedly writing "axes = FALSE, box = FALSE" into the `plot` function, even with Rstudio's handy tab completion. This repeated use of the exact same code is the sort of situation that calls for writing your own function.  

```{r, eval = FALSE}
# x <- chirpsz[[1]]; x <- 1:10
plot_noaxes <- function(x, axes = FALSE, box = FALSE, mar = c(0, 0, 1, 4), 
                        ...) {
  if(!class(x) %in% c("RasterLayer", "RasterStack", "RasterBrick", "Extent")) {
    stop("This function is intended for rasters only", call. = FALSE)
  }
  par(mar = mar)
  plot(x, axes = axes, box = axes, ...)
}
```

The function above (not run in the block above, because it is written into `geospaar`) takes care of the axes and box problem by setting their default arguments to FALSE. It also sets the default plot margins to the ones we have mostly been using so far (leaving room on the right for the legend and at the top for a title), and it checks whether the object being passed to it belongs to one of the raster classes (failing if it doesn't). Otherwise, it retains all of the ohter functionality of `raster::plot`, and has the "..." argument, meaning you can pass other eligible arguments to it. 

Let's see how it works:
```{r}
plot_noaxes(chirpsz[[1]])
```

That will make plotting easier moving forward. 

[Back to top](#rasterintro)

### Aggregating/disaggregating

To change to resolution of a raster object, you can use `aggregate` to make a coarser resolution, or disaggregate to decrease the resolution. To make `chirpsz` match the 0.1 resolution of `distsr` (the rasterized districts), we do this:

```{r}
chirpsz1agg <- aggregate(x = chirpsz[[1]], fact = 2, fun=mean)
chirpsz1agg
```

We aggregate the first layer of `chirpsz` by a factor of 2 ("fact = 2"), taking the average of the aggregated pixels ("fun = mean"). Since the starting resolution was 0.05, doubling the pixel size takes it to 0.1. We could have chosen to aggregate all layers, and we could have chosen a different aggregation function (e.g. `sum`, `max`).

To disaggregate, there are two options:
```{r}
chirpsz1km <- disaggregate(x = chirpsz[[1]], fact = 5)
# chirpsz1km <- disaggregate(x = chirpsz[[1]], fact = 5, method = "bilinear") 
chirpsz1km
```

The first option is the default one, which just breaks apart each pixel into the number of smaller new pixels specified by the factor, assigning each new pixel the same value as its larger parent. Here we specified a factor of 5, leading to an output resolution of 0.01 (~1 km), and thus 25 times the number of pixels as in the original `chirpsz[[1]]` (run `ncell(chirpsz1km) / ncell(chirpsz[[1]])` to see).

The second way (commented out), is to pass the "method = bilinear" argument, which interpolates during disaggregation. In this case, `disaggregate` does the job using the `resample` function, which we will see next.  

<span style="color:blue">Exercise 7</span><a name="exercise7"></a>:
___Crop `chirpsz[[1]]` using the extent of `districts[57, ]`, and disaggregate it to 0.01 resolution using both the default and bilinear methods. Plot the results side by side using `plot_noaxes`___ ([Exercise index](#unit2exercises))

[Back to top](#rasterintro)

### Resampling

Resampling is done for many reasons, but one particularly common case is as a final step following aggregation or disaggregation, when it is needed to co-register the resulting grid to another grid. 

```{r, error=TRUE}
chirps125 <- aggregate(x = chirpsz[[1]], fact = 5)  # no fun b/c default is mean
s <- stack(chirps125, farmersr)  # fails 

par(mar = c(1, 1, 1, 1))
plot(extent(chirps125), axes = FALSE, col = "blue")
plot(extent(farmersr), add = TRUE, col = "red")

```

After aggregating `chirpsz` layer 1, we try and fail to stack the result with `farmersr`, because (as the plot of extents show, and the warning tells) the two objects have different extents. So, another approach is needed: 

```{r}
farmersr_rs <- resample(x = farmersr, y = chirps125) 
s <- stack(chirps125, farmersr_rs)  
names(s) <- c("rain", "farmer_count")
plot_noaxes(s)
```

We resample `farmersr` to `chirps125rs`, since `chirps125rs` has the larger extent. We can then stack and perform subsequent analyses on both, e.g. finding areas where rainfall exceeded 1 mm and where there was more than 1 farmer:

```{r}
plot(s$rain > 1 & s$farmer_count > 1)
# plot(chirps125 > 1 & farmersr > 1)
```

[Back to top](#rasterintro)

## Raster analyses

Let's move on now to some analyses with raster data. 

### Global statistics

The most basic analyses to perform on rasters is calculate global summary statistics, i.e. statistics calculated across all cell values:

```{r}
cellStats(x = chirpsz[[1]], stat = "mean")  # for a single date
cellStats(x = chirpsz[[c(5, 7, 14)]], stat = "mean")
summary(chirpsz[[1:3]])
```

`cellStats` lets you calculate specific statistics from the cell values of a lone `RasterLayer`, or for just a single, multiple, or all layers in a `RasterStackBrick`. `summary` returns the quintile values and counts the number of `NA` or no data cells. Both functions by default remove NA values (which are in many if not most rasters), which is something that usually has to be specified when trying to apply these statistical functions to an ordinary vector, e.g. 

```{r}
v <- values(chirpsz[[1]])
mean(v) 
mean(v, na.rm = TRUE)
```

`v` is a vector of all of the values from the first layer in the rainfall brick, including its NA values. `mean` returns an `NA` if you don't tell the function to remove `NA` values first.  

> This is important to remember, because both spatial and non-spatial data often have missing values, so you will have to deal with them explicitly in many cases. 

Okay, here's a more programmatic way of using `cellStats`:

```{r}
# Block 1
rain_stats <- lapply(c("mean", "sum", "sd", "cv"), function(x) {
  cellStats(x = chirpsz, stat = x)
})
names(rain_stats) <- c("mean", "sum", "sd", "cv")

# Block 2
dates <- names(rain_stats[[1]])
dates <- as.Date(gsub("Y", "", dates), "%y%j")  # convert names to date vector

# Block 3
par(mfrow = c(2, 2), mar = c(4, 4, 2, 2))
for(i in 1:length(rain_stats)) {
  plot(x = dates, y = rain_stats[[i]], type = "l", xlab = "Date", 
       ylab = paste("Rain", names(rain_stats)[i]), col = "blue")
}
```

Block 1 leverages `lapply` to calculate 4 statistics over all dates in `chirpsz`, meaning that we get a time series for each statistic as calculated over all of Zambia. 

Block 2 is just converting the character vector that gives the name for each date into a vector of actual dates, using `gsub` to first replace the "Y" in each name, and then `as.Date` to parse the remaining numbers into an actual date. The "%y%j" construction tells `as.Date` which parts of the character string relate to which part of a date: %y = two digit year; %j = julian day; placed next to one another %y%j means these two elements are immediately adjacent to one another in the string. 

> Practice: Try `as.Date("10-11-2017", "%m-%d-%Y")`, `as.Date("10112017", "%m-%d-%Y")`, and `as.Date("10112017", "%m-%d-%Y")` to get a better sense of how that works. 

Block 3 plots the time series, using the `dates` vector to provide the x variable. 

> The results in the plot above are actually quite interesting. The top two panels show quite clearly the start of the rainy season (just after Nov 8). The bottom two panels show two measures of variability, the standard deviation (SD) and coefficient of variation (CV, i.e. SD / mean). These two measures summarize the spatial variability of rainfall falling across Zambia on each day--SD increases as the amount of rain increases (which is expected--SD is usually positively correlated with the mean), whereas CV declines as rainfall increases, indicating that a progressively larger area of the country receives rainfall as the month progresses, so there is less spatial variability. There is a big spike in CV on November 8, which corresponds to a drop in mean and total rainfall. However, that drop masks the fact that there are a few small patches that received a decent amount of rainfall, thus leading to a high CV (see next plot below).  

```{r, fig.width=5, fig.height=4}
plot_noaxes(chirpsz[[15]], main = paste("CV =", round(rain_stats$cv[15])))
```

Another way to summarize raster data is visually, using a histogram (raster has a generic `hist` function)
```{r, fig.width=7, fig.height=4}
par(mfrow = c(1, 3))
hist(chirpsz[[15:17]], col = "blue", xlab = "mm")
```

This variant plots a histogram per layer in the `Raster*` object (but we told it to plot 1 row, 3 columns, instead of the default (2 rows, 2 columns)).  

`freq` is another way to summarize raster values that is similar to `hist` but without the automatic plot.
```{r}
f <- freq(chirpsz[[1]])
f
```

Here we apply `freq` to a dataset with continuous values, although this function is probably best reserved for categorical rasters. However, it produces reasonable results here.

[Back to top](#rasterintro)

### Local statistics

The previous gives us statistics calculated across the entire raster. These summaries, and other analyses, can also be done locally.  

#### Zonal

One way local statistics can be calculated is by defining zones and then calculating statistics within those zones. 

```{r}
# zonemu <- zonal(x = chirpsz, z = distsr, fun = "mean")  # fail b/c extent
distsr_rs <- resample(x = distsr, y = chirpsz, method = "ngb")  # match extent
zonemu <- zonal(x = chirpsz, z = distsr_rs, fun = "mean")
head(zonemu)[, 1:5]
```

That creates a matrix (truncated here) of mean rainfall within each zone ( district), by date. 

#### `subs`

To map the zonal statistics onto their zones, we need to use another function, `subs`.

```{r}
distr_rfmu <- subs(x = distsr_rs, y = data.frame(zonemu)[, 1:2], by = "zone")
plot_noaxes(distr_rfmu)
```

`subs` replaces the values in a raster by other values contained within a `data.frame` that correspond to a variable that has the same values as those in the raster (in this case the district IDs). `subs` can be slow-ish on big rasters. 

<span style="color:blue">Exercise 8</span><a name="exercise8"></a>:
___Use zonal stats on `farmersr_rs` to calculate the total number of farmers per district, and then map them onto the districts as we did above. Remember that `farmersr_rs` is a coarser resolution than `distsr_rs`, but aggregating the districts further would lose a lot information. Disaggregating is also problematic because it messes up the zonal stats. Better to first re-rasterise `farmers2` to the 0.1 resolution, using `distsr_rs` as the reference (to get the right extent) and then calculate and map zonal stats___ ([Exercise index](#unit2exercises))

[Back to top](#rasterintro)

#### Focal

Another way of calculating image statistics is to use a moving window/neighborhood approach. This is done with the `focal` function, which has a great many functions that you can apply with it. We will just show you the mean (also known as a low pass filter), and a few permutations of it here to illustrate the concept.  

> Disclaimer: This section assumes that you have applied moving window functions/low pass/high pass filters in your GIS/remote sensing classes so far, and thus are familiar with the calculations. If not, please be sure to ask about this in class.  

```{r, fig.width=6, fig.height=4}
# Block 1
wmat <- matrix(1 / 9, nrow = 3, ncol = 3) 
chirps1_focmu1 <- focal(x = chirpsz[[1]], w = wmat) 

# Block 2
wmat <- matrix(1, nrow = 3, ncol = 3) 
chirps1_focmu2 <- focal(x = chirpsz[[1]], w = wmat, fun = mean) 

# Block 3
wmat <- matrix(1, nrow = 5, ncol = 5) 
chirps1_focmu3 <- focal(x = chirpsz[[1]], w = wmat, fun = mean) 

# Block 4 
wmat <- matrix(1, nrow = 5, ncol = 5) 
chirps1_focmu4 <- focal(x = chirpsz[[1]], w = wmat, fun = mean, na.rm = TRUE) 

# Block 5
wmat <- matrix(1 / 9, nrow = 5, ncol = 5) 
chirps1_focmu5 <- focal(x = chirpsz[[1]], w = wmat, na.rm = TRUE) 

# plots
l <- list(chirps1_focmu1, chirps1_focmu3, chirps1_focmu4, chirps1_focmu5)
titles <- c("3X3 NAs not removed", "5X5 NAs not removed", 
            "5X5 NAs removed properly", "5X5 NAs removed improperly")
par(mfrow = c(2, 2))
for(i in 1:length(l)) {
  plot_noaxes(l[[i]], main = titles[i])
}
```

We have 5 variants above. In Block 1, we calculate the focal mean the recommended way, which is to: 

1. Define a matrix (`wmat`) that contains the weights that `focal` applies to each pixel when making neighborhood calculations.  In this case, the matrix is 3X3, which is the size of our moving window, and the weights are distributed equally across all pixels and sum to 1 (each gets a weight of 1/9)
2. `focal` then passes over each image pixel, and multiplies those weights by each pixel value in the neighborhood, and then sums those to get the mean 
3. It sums the values because `sum` is the default value of the argument "fun" in the function `focal`, which is why we have not even specified the argument "fun" in Block 1

Note that the way `focal` is coded here does not remove NA pixels, thus any neighborhood having even a single NA pixel is itself turned into NA, i.e. all 9 pixels in the neighborhood. Thus the entire boundary of Zambia is trimmed down accordingly (by 2 pixels). This result is illustrated in the upper left panel of the plot above. 

Block 2 is a slower way of doing the same thing. It pass the `mean` function to `focal`'s "fun" argument. The weights matrix in this case has 1s throughout; since we are not using the default "fun=sum" in `focal` and `mean` is doing the work, we can't modify the values of the pixels if we want want the correct mean. We also do not remove NA values from the calculation, so the results are identical (and thus not plotted below). 

In Block 3, we use the same approach as in Block 2, but expand the neighborhood to 5X5. You will see in the plot above (upper right) that Zambia has shrunk even more (by 4 pixels) as a result. 

In Block 4, we again pass `mean` to `focal`, and have a 5X5 neighborhood, but here we specify "na.rm = TRUE", which means that focal passes "TRUE" to the "na.rm" argument of `mean`, thus NAs are removed from each neighborhood before calculating the mean, and boundary pixels aren't lost (note the larger area in the lower left plot above). This is the correct way to remove NAs when calculating focal means.  

In Block 5, we see the improper way of removing NAs from focal calculations, this time using the faster approach demonstrated in Block 1. The lower right plot shows how pixels near Zambia's border have artificially low values, which results from the fact that this method does a weighted mean, but because NAs are removed, the weights do not sum to 1 and thus the mean is underestimated. 

That's a look at `focal`. Now we are going to have you apply in the next exercise:

<span style="color:blue">Exercise 9</span><a name="exercise9"></a>:
___Use `focal` to calculate for `chirpsz[[20]]` the i) standard deviation within a 3X3 and 5X5 window, and ii) the maximum value in each 3X3 and 5X5 neighborhood. Do not remove NAs. Combine the results in a list, as above, and then plot them with descriptive titles using a `for` loop and the `plot_noaxes` function with descriptive titles.___ ([Exercise index](#unit2exercises))

[Back to top](#rasterintro)

### Analyzing the Z dimension

If we have a `RasterStackBrick`, we have three dimensions (x, y, z). Often we want to analyze the values in the Z dimension, which may represent time, spectral bands, or unrelated spatial predictors in a model. 

The workhorse for doing this sort of analysis is `calc`, which allows you to apply almost any function to the Z-dimension of a `RasterStackBrick`. 

```{r}
# Block 1
rain_zmu <- calc(x = chirpsz, fun = mean)
rain_zsd <- calc(x = chirpsz, fun = sd)
rain_zrng <- calc(x = chirpsz, fun = range)

# Block 2
rain_zstack <- stack(rain_zmu, rain_zsd, rain_zrng)
names(rain_zstack) <- c("Mean", "StDev", "Min", "Max")

plot_noaxes(rain_zstack)

```

Block 1 passes `mean`, `sd`, and `range` to "fun" in `calc`. Note that `range` always returns two values, so `calc` conveniently returns a two-layer brick that contains the minimum in the first layer and the maximum in the second. 

In Block 2 we then stack the three outputs, and rename the layers something meaningful so that `plot_noaxes` can plot them all at once. 

You will see from the resulting plot that "Min" has only one value, 0, which makes sense for a rainfall time series (every pixel is likely to have at least one day of no rainfall in a month).

So that's it, except for your final exercise: 

<span style="color:blue">Exercise 10</span><a name="exercise10"></a>:
___Use `calc` with `chirpsz` to calculate the total rainfall in the time series, the coefficient of variation, and the median. Stack the results and plot them with meaningful titles using `plot_noaxes`, outputting plots on 1 row with 3 columns.___ ([Exercise index](#unit2exercises))

[Back to top](#rasterintro)

# Section 3{#section3}

[Back to top](#rasterintro)

<span style="color:blue">Exercise 1</span><a name="exercise15"></a>: ___
___ [Exercise index](#unit3exercises)















